---
title: "Repertoire"
author: "Gestural Origins"
date: "`r format(Sys.time(), '%d -%m -%Y')`"
output:
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    toc: yes
    fig_width: 8
    fig_height: 6
    fig_caption: yes
    number_sections: yes
fontsize: 12pt
spacing: double
fig_caption: yes
indent: yes
geometry: margin=1in
mainfont: Calibri
sansfont: Calibri
monofont: Calibri
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message=FALSE, 
                      warning=FALSE)
options(digits=3)
library(kableExtra)
library(knitr)
library(tibble)
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(embed)
library(BayesLCA)
library(discrim)
library(naivebayes)
library(rpart.plot)
library(parallel)
library(doParallel)
```

# What's New - 19/07/22?

-   Implemented suggested changes to this document
-   Gave repertoire stuff its own GitHub repository and checked it worked

# What's New - 08/07/22?

-   Focussed data only on East African Chimpanzees
-   Got the 'cleaned' data from Alex and Gal so will not remove data anymore - however, will remove the Repetition on the Locomote and Spin variables and the Flexion and Orientation on Presents
-   Lumped pre-split gesture actions (e.g., all the *Hit*) to check
whether the pre-split decisions hold
-   Increased cut off value below which we ignore morphs to 5
-   Included broader cut off value below which a gesture action is just
thrown out - set to 10 now
-   Those four steps cut the number of gesture actions we are looking at
to about 50, so much more manageable
-   Removed a lot of the text for the raw probabilities - while these were interesting in the begining, we never actually used them for anything so they are just clutter
-   Called everything 'morphs'
-   Introduced functions that can calculate the entropy of Goals/Groups
etc within a gesture action and check whether any modifier reduces
that entropy (i.e., does that modifier make us more certain about
meaning); also works with morphs (i.e., is the meaning of a morph
more certain than of the gesture action as a whole?)
-   Those functions will be used to determine morphs of interest, but
also to find out whether there are any modifiers that just never do
anything
-   Morphs are now evaluated to see whether they fulfill any of the
following criteria:
-   have at least 5 occurrences AND

-   only occur in one Goal OR

-   only occur in one group OR

-   reduce entropy for Goal OR

-   have probability and specificity for one or combination of
modifiers (e.g., all *beckon* with head are in one morph)
-   If they fulfill any of these, they are marked as *clear morphs*,
because there is a good reason to check whether they are of interest
for further analyses
-   For all other morphs, we'll have to go check what is going on
-   Included a function that creates similarities between gesture
actions - can be used to check whether there are any morphs that are
more similar to other gesture actions than to the centre of their
own gesture action
-   Realised that the main attribute of morphs has to be that they are mutually exclusive, clearly identifiable, and have to include every case in the dataset. Changed that to be the first step to fix after morphs are created.
-   Moved away from UMAP + clustering algorithm (which is the correct approach for numeric variables) and towards Bayesian Latent Class Analysis (which does model-based clustering specifically for categorical variables, without the pesky dimension reduction step). This also has reduced the number of morphs dramatically.


# Rationale

We are trying to establish a repertoire that provides a useful level of analysis for exploring ape gesture use, one that parses the gestures into units that are relevant to the apes, and one that allows us to describe meaning and explore possible syntax, given the data coded by the Wild Minds Lab. We recognise that other levels of repertoire are possible. For example more fine grained splitting of morphs incorporating more descriptive features, may allow use to explore tone or emphasis. Importantly, there is no 'true' repertoire, as long as we cannot ask the chimpanzees which particles of information they process - we can generate different repertoires of different levels of detail and judge them by their usefulness and internal consistency. By generating the most fine-grained repertoire yet, we can subsequently lump and split depending on the dataset and question at hand. Essentially, for any given level of analysis, we have to show that
every 'gesture' in the coding scheme is exactly one gesture, and that no
two distinct gestures are actually one gesture. Here, we focus on the
first part of that question: are coded gestures actually one gesture and
not several very similar ones, distinguished by some modifying feature?

To move away from a purely *a priori,* human-centred approach, the
coding scheme used by the lab has been changed to not only include a
*gesture action* (the movement pattern that lets human observers detect
the gesture), but also a large number of modifying parameters or
*modifiers.* These specify more detailed aspects of each movement (e.g.,
which limb was used, how far the limb was stretched, etc). The challenge
now is to establish whether there are clustered combinations of gesture
actions and modifiers that would indicate a current gesture action is
indeed two gestures: for example, *arm raise* with one arm vs *arm
raise* with both arms. We will refer to the combination of gesture
action and modifiers as **Gesture Morphs**. We will attempt identifying
morphs that could indicate meaningful variation within a gesture action
without referring to the meaning/goal of gestures, and also without
referring to sequential information, because those will be the outcome
variables for later projects - if we involve them here, the risk is our
reasoning becomes tautological.

# Approach

There are currently around 110 gesture actions in the coding scheme and
probably about 8-12 modifiers of interest, many with multiple possible
levels. This would leave us with potentially an astronomically high
number of combinations. Our approach here will be to set a number of
rules to identify possible morphs that could be considered distinct
signals. One problem we face is that many modifiers are only defined for
a small subset of gesture actions - we therefore need rules that are
gesture action specific. We will set exclusion rules for both gesture
actions and modifiers. For modifiers we will set exclusion rules across
gesture actions (when do we just eliminate a modifier because we assume
that it does not contain information about any gesture action?) and
within gesture actions (when do we assume that a specific modifier does
not contain information about a specific gesture action?). We are trying
to create reproducible and replicable definitions of the gesture
repertoire, and the dataset for this project continues to expand. Hence,
all scripts take their starting point from the raw data as extracted
from the Filemaker library of the project; data will be processed; and
we will then take the appropriate steps to narrow down the repertoire
based on pre-defined rules.

One important thing to note is that, in the original coding process, there were some gesture actions who were distinguished from each other by the application of a modifier - for example, *HitOther* was different from *HittingOther* because of the presence of the modifier *Repetition*. However, for the latest version of this project, we combine these gesture actions *a priori* - our goal is to have a set of gesture actions where no modifier is a **necessary condition** for any gesture action (even though the gesture actions are often **sufficient conditions** for most modifiers).

## Ruleset

```{r cutoff, echo = FALSE}
cutoff_overall <- 5 # cutoff for modifiers and morphs
cutoff_action <- 10 # cutoff for gesture actions
```

All rules will be based on probabilities (unconditional and conditional)
and comparisons between observed and expected probability distributions.
We have to set a cutoff value throughout - how many cases of a modifier
level do we have to see to assume we are not simply looking a random
variation or coding error? Here, we set the cutoff at
`r print(cutoff_overall)` for now. This can be varied to check
replicability of this decision.

### Exclusion rules for gesture actions

Gesture actions are only excluded if fewer than `r cutoff_action` cases are available for the gesture action. We included this threshold because we essentially cannot make meaningful statements about the reliability of any morph assignment to these gesture actions, so they represent noise. A list of these can be found below.

### Exclusion rules for modifiers

#### Exclusion rules for modifiers across gesture actions

Our main goal with the modifiers is to reduce both *redundancy* and *noise* to get to the actual signal. There are some scenarios that would lead to us removing a modifier
completely from the dataset because it cannot possibly provide
independent information.

1.  Only one option of the modifier is ever used.
2.  The modifier is never applicable.
3.  The modifier is perfectly explained by another modifier (very high
conditional probability).

In the latter case, we need a system to combine two modifiers, remove
one and store that information, or just remove one option from a
modifier. For example, it is possible that the arm is only ever fully
stretched if the hand is also fully stretched - in that case, 'fully
stretched limb' could become its own modifier, reducing redundancy.

To do this, we need to calculate the unconditional and conditional
probabilities and mutual information of modifiers across gesture types.
If the conditional probability of two modifiers are 1, we can consider
them equivalent.

#### Exclusion rules for modifiers within gesture actions

After we have reduced redundancy and possible actions across gesture
types, it will become important to look within gesture types and
determine where we find meaningful variation that could represent
distinct clusters. First, we use the same process we used across
gestures to narrow down or search to modifiers that show enough
information within a gesture type.

Within each gesture type, we will apply the same exclusion rules:

1.  Only one option of the modifier is ever used within the gesture
type.
2.  The modifier is never applicable within the gesture type.
3.  The modifier is perfectly explained by another modifier (very high
conditional probability) within the gesture type.

In the latter case, we need a system to combine two modifiers, remove
one and store that information, or just remove one option from a
modifier. For example, it is possible that the arm is only ever fully
stretched if the hand is also fully stretched - in that case, 'fully
stretched limb' could become its own modifier, reducing redundancy.

To do this, we need to calculate the unconditional and conditional
probabilities and mutual information of modifiers within all gesture types.
If the conditional probability of two modifiers are 1, we can consider
them equivalent.

At the end of this process, we should have a list of gesture actions
that only ever see one expression and can be considered stand-alone
morphs.

One important problem are *NAs* in modifiers that are otherwise
informative (i.e., have variation). We would be unable to assign that
case to any Morph with certainty, unless the modifier is unimportant for
Morph clustering. Thus, when we have a modifier that has multiple
levels, gesture events with NA in that modifier are removed from the
dataset.

#### Detect uninformative modifiers

There will be some modifiers that do not fulfil the exclusion rules but
do not carry relevant information for the gesture action. One example of
this could be laterality of hand use: individuals sometimes use their
left or right hand, but this is no indication for changed information content.
Alternatively, something like arm flexion could indicate how strongly an
individual wants the recipient to react - across gesture actions.

One way to establish this is to compare the distribution of modifier
options within each gesture actions and compare it to all cases in which
this modifier was applicable. For example, if individuals on average use
their left hand 40% of the time, the fact that they also use it 40% of
the time when doing a *reach* probably means that handedness of the
*reach* is not an important distinction.

Another approach would be to bring back meaning (in the form of Goals of gesture actions) and test whether a modifier somehow contains information about the meaning - do they reduce our uncertainty (in the form of entropy) of what the outcome of an interaction will be?

To test this, I would create a distribution of expected values for each
modifier, based on all gesture actions where the modifier would be
applicable. We would do this by bootstrapping subsets of the data,
preferably on the individual-level (repeatedly kicking out individuals
and calculating probabilities) to account for individual-level
consistency.

#### Detect modifiers that are expressions of individual differences

Another situation that could arise is that modifiers show different
expressions within gesture actions, but this is the result of
inter-individual differences in expression: one individual always flexes
their arm fully, another always leaves it bend. This might also be the
result of other parameters (e.g., sex, age, rank). However, these latter
parameters might not always be available, while individual identity
mostly is.

To test this, I would create conditional probabilities of modifiers
GIVEN the gesture action AND the sender. This might be futile, because
for many individuals, insufficient data will be available. We would mark
gesture/modifier combinations where we see population-level diversity of
choice, but within-individual determinism.

#### Identify potential splits

For each gesture action, we should have at this point removed a large
number of modifiers as uninformative, because they are either
non-applicable, fixed, explained by other modifiers, or variation is
random.

The potential gesture morphs that are still around should show variation
within gesture actions, variation should be independent from other
modifiers, variation should not be random, and sufficient cases should
exist to have some certainty that we are not dealing with a random
fluke.

I would start by producing a list of these and then proceed from there.
Another approach we will explore is using dimension reduction and
cluster detection algorithms to set the rules - what clusters of
modifiers within gesture actions would the computer come up with?

### Verification

We need to somehow check whether the resulting morphs make any
sense. I can think of a couple of ways.

-   keep a subset of the data away from the original analysis and test
whether the splits make sense in that subset. Alternatively,
bootstraps.

-   For gesture actions that are already split this way (e.g., *Hit* vs
*Hitting*), check whether other modifiers split in predictable ways.

-   Check whether potential splits would systematically differ across
sites or species.

-   Check whether resulting morphs reduce uncertainty about interaction outcomes/goals

-   Check whether morphs show high similarity with regard to the distribution of Goals that we observe them in - if all morphs in a gesture action are more similar to each other than to any other morph, and I can correctly predict that gesture action of a morph just by knowing the distribution of Goals, they probably add little for future studies.

\newpage

# Data Cleaning

I have tried to collect all functions and data for this project (and a
considerable number of other ones) in package-form. This can be loaded
by the user after downloading it from Github.

## Get Data and Scripts

```{r libraries}
devtools::load_all("~/GitHub/Morph_Repertoire/wildminds/R/")
```

### Read data into object

First, we read the dataset into an object called 'gesture.data'. This
contains the uncleaned data as it is extracted from Filemaker. The
dataset is already part of the wildminds package

```{r read_data, echo = T}
gesture.data <- gesture_data
```

### Add video information

Before we start with looking at the repertoire, we need to clean the
data. There are currently a number of issues with the dataset.
Information about the field site, date, coder identity, etc, are
currently only coded within the clip name and the communication code.
Therefore, I have added some helper functions that extract that
information and allow users to add it to their data frame. This is
currently still hampered by the fact that the clip names are a disaster
and that the bonobos do not follow the same recording number format as
everything else, and also use different names for gesture actions and
some modifiers. There is uncertainty about how we will use the mountain
gorillas as well, and the West African chimpanzees. I have currently
excluded them for that reason - the dataset contains information from
several East African chimp field groups (Issa, Waibira, Sonso, Kalinzu).
This can all be updated as we go along

```{r video_info, echo=T}

# Deconstruct clip name ---------------------------------------------------

gesture.data$Date <- date_from_clip(gesture.data$Clip_name)
#gesture.data$Clip_nr <- clipnr_from_clip(gesture.data$Clip_name)

# Get observer, field site, and group from communication numbers ----------
gesture.data$Com_number <- str_replace(gesture.data$Com_number, 'C', '')

gesture.data$Social_unit <- 
  info_from_Com_number(com_number_column = gesture.data$Com_number, output = 'group')
gesture.data$Coder <- 
  info_from_Com_number(gesture.data$Com_number, output = 'coder')
gesture.data$Species <- 
  info_from_Com_number(gesture.data$Com_number, output = 'species')

### We'll remove everything that is not an East African chimpanzee
gesture.data <- gesture.data %>%
  filter(Species=='EAC')

```

## Get dataset for Repertoire

The data, as extracted from the database, still have the formatting that
was used in ELAN. This might not really be everyone's deal, because it
is hard to remember what *App_Undir* stands for 5 years into a project.
Thus, we add a function that does a number of steps. First, all the NA
and NV values are turned into NotApplicable and NoValue to avoid
confusion with R's internal NA values. The user can decide to
*clean.values*, which if applied leads to all levels of all variables in
the dataset being given reasonable names rather than shortcuts. For
example, *App_Undir* becomes *ApparentlyUndirected*. *clean.names*
cleans the column names, which were not more informative than the
levels. We should also exclude some events, because they cannot
reasonably be considered gestures. Currently, if you set
*exclude.unknown.gestures* to TRUE, the function excludes those events
where *Gesture_record* does not give one clear identifiable gesture
action; the different exclusion rules are explained in the script of the
function.

```{r clean_data, echo=T}

clean.data <- clean_function(data = gesture.data,
                             clean.value.levels = TRUE,
                             clean.col.names = TRUE,
                             exclude.unknown.inds = FALSE,
                             exclude.unknown.goal = FALSE,
                             exclude.unknown.gestures = TRUE,
                             exclude.incomplete.coding = FALSE, 
                             exclude.unknown.direction = TRUE, 
                             exclude.goal.unmet = FALSE, 
                             exclude.no.response.waiting = FALSE, 
                             exclude.no.persistence = FALSE
)
```


```{r cleaning, echo = FALSE}
clean.data$Gesture_record = 
  clean.data$Gesture_record %>% 
  str_replace(pattern = 'TouchLongObject', replacement = 'TouchObject') %>% 
  str_replace(pattern = 'Stomping2ftObject', replacement = 'StompingObject')

```


After we do this, many of the columns of the dataset will still have a
rather large number of levels, many of which do not have a clear meaning
for us or provide unnecessary detail. For example, there are 24
different body parts. There are also usually several different pieces of
information ('unknown', 'not applicable', 'no value') that might be
important to differentiate for some projects, but for most will just
mean 'no information available for this variable' and should be
considered NA in R. The *reduce_levels* function removes some of this
unnecessary information. Note that how levels are lumped can still be
discussed and might not be the same for all projects - if you just want
some levels lumped, just replace the relevant columns with the previous
version of the cleaned data.

```{r reduce_levels, echo=T}

clean.data.reduced <- reduce_levels(data = clean.data, 
                                    col_names = 'renamed',
                                    reduce.nas = TRUE,
                                    reduce.goals = TRUE,
                                    reduce.body.part.signaller = TRUE,
                                    reduce.body.part.contact = TRUE,
                                    reduce.object.used = TRUE,
                                    reduce.object.contacted = TRUE, 
                                    reduce.laterality = TRUE)
```

One important thing that gets reduced here are the Goals - the conventions used can be found here: https://docs.google.com/spreadsheets/d/1reh5w1LMrvmr8U_o44qGbvuoWlmTvwYP/edit#gid=518609932 

Those are currently the main cleaning functions. I will see that I
compartmentalise the functions more as time goes on, to allow users to
change very specific variables rather than the whole dataset, and set
parameters more precisely.

### Detect possible errors

Some gesture actions are restricted by the protocol to only take certain
values during coding. For example, the difference between *Hit* and
*Hitting* should be that *Hit* occurs only once, while *Hitting* implies
repetition. If we see coded cases where *Hitting* has no repetition,
then we should be suspicious, because we potentially introduce variation
that should not exist. Often, this leads to one or two cases out of
several hundred of a gesture action taking very different form. These
coding anomalies should be detected as early as possible. There is a
function, **error_detection**, where the user can specify an error list
that contains the gesture action, modifier, and level that should not
occur, and the function pops out all cases in the dataset where this
combination occurs, so we can have a look at them and decide what to do.
As the coders had time to check and have confirmed that all irregularities are intended now, I will no longer remove these data.

```{r find_errors, echo= TRUE, eval=FALSE}

# potential_errors <- error_detection(
#   data = clean.data.reduced, 
#   col_names = 'renamed')
# 
# nrow(potential_errors)

# clean.data.reduced <- clean.data.reduced[
#   !(1:nrow(clean.data.reduced) %in% 
#       potential_errors$row.number),]
```

### Lump gesture actions

During coding, some gesture actions were split a priori based on
modifiers (e.g., *HitOther* and *HittingOther* are the same movement,
but one has repetition and the other doesn't). Equally, some gesture
actions were split based on whether they were *directed* (e.g.,
*PullDirected*). We will remove these decisions here and lump those
gesture actions, to check whether these splits were meaningful in the
first place.

```{r lump_gesture_actions}

split_list <- list(
  # Hit object
  data.frame(original = 'HitObjectObject', lumped = 'HitObject'),
  data.frame(original = 'HittingObject', lumped = 'HitObject'),
  data.frame(original = 'HittingObjectObject', lumped = 'HitObject'),
  # Hit Other
  data.frame(original = 'HitObjectOther', lumped = 'HitOther'),
  data.frame(original = 'HittingOther', lumped = 'HitOther'),
  data.frame(original = 'HittingOtherObject', lumped = 'HitOther'),
  data.frame(original = 'HittingObjectOther', lumped = 'HitOther'),
  # Hit Self
  data.frame(original = 'HittingSelf', lumped = 'HitSelf'),
  # Hit Other Self
  data.frame(original = 'HittingOtherSoft', lumped = 'HitOtherSoft'),
  # Hit Object Soft
  data.frame(original = 'HittingObjectSoft', lumped = 'HitObjectSoft'),
  # Hit Bystander
  data.frame(original = 'HittingBystander', lumped = 'HitBystander'),
  # Hit Other Clap
  data.frame(original = 'HittingOtherClap', lumped = 'HitOtherClap'),
  # KnockObject
  data.frame(original = 'KnockingObject', lumped = 'KnockObject'),
  # Poke
  data.frame(original = 'Poking', lumped = 'Poke'),
  # StompObject
  data.frame(original = 'StompingObject', lumped = 'StompObject'),
  # StompOther
  data.frame(original = 'StompingOther', lumped = 'StompOther'),
  # Directed
  data.frame(original = 'PresentDirected', lumped = 'Present'),
  data.frame(original = 'SwingDirected', lumped = 'Swing'),
  data.frame(original = 'PushDirected', lumped = 'Push'),
  data.frame(original = 'PullDirected', lumped = 'Pull')
) %>% 
  bind_rows()


for(i in 1:nrow(split_list)){
  clean.data.reduced$Gesture_record[clean.data.reduced$Gesture_record == split_list$original[i]] = 
    split_list$lumped[i]
}

for(i in 1:nrow(split_list)){
  clean.data$Gesture_record[clean.data$Gesture_record == split_list$original[i]] = 
    split_list$lumped[i]
}

```

### Remove rare gesture actions

Many gesture actions occur at very low frequencies; for example,
`r (clean.data.reduced$Gesture_record %>% table < cutoff_action) %>% sum`
gesture actions occur fewer than `r cutoff_action` times in this
particular dataset. Trying to establish variation within those would be
fairly difficult and hard to justify; thus, we restrict our dataset to
gesture actions that have at least `r cutoff_action` occurrences. The following gesture action are removed:

```{r rare_ga}
(clean.data.reduced$Gesture_record %>% 
                   table)[clean.data.reduced$Gesture_record %>% 
                            table < 
                            cutoff_action] %>% 
  data.frame() %>% 
  rename('Gesture_record' = '.') %>% 
  rename('Frequency' = 'Freq')  %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 12)
  

```


```{r remove_rare}
clean.data.reduced <- 
  clean.data.reduced %>% 
  filter(Gesture_record %in% 
           names(clean.data.reduced$Gesture_record %>% 
                   table)[clean.data.reduced$Gesture_record %>% 
                            table >= 
                            cutoff_action])

```

This leaves us with
`r length(unique(clean.data.reduced$Gesture_record))` instead of
`r length(unique(clean.data$Gesture_record))` gesture actions.

### Remove Flexion and Orientation for Present

*Present* is not supposed to have Flexion and Orientation coded, but somehow does for some of the students. Thus, I manually remove those until this has been cleaned.

```{r}

clean.data$Flexion[clean.data$Gesture_record == 'Present'] = NA
clean.data$Orientation[clean.data$Gesture_record == 'Present'] = NA

clean.data.reduced$Flexion[clean.data.reduced$Gesture_record == 'Present'] = NA
clean.data.reduced$Orientation[clean.data.reduced$Gesture_record == 'Present'] = NA
```

### Remove Repetition for Spin and Locomote variables

*Present* is not supposed to have Flexion and Orientation coded, but somehow does for some of the students. Thus, I manually remove those until this has been cleaned.

```{r}

clean.data$Repetition_count[clean.data$Gesture_record == 'LocomoteGallop'] = NA
clean.data$Repetition_count[clean.data$Gesture_record == 'SpinPirouette'] = NA
clean.data$Repetition_count[clean.data$Gesture_record == 'SpinRoulade'] = NA
clean.data$Repetition_count[clean.data$Gesture_record == 'SpinSomersault'] = NA

clean.data.reduced$Repetition_count[clean.data.reduced$Gesture_record == 'LocomoteGallop'] = NA
clean.data.reduced$Repetition_count[clean.data.reduced$Gesture_record == 'SpinPirouette'] = NA
clean.data.reduced$Repetition_count[clean.data.reduced$Gesture_record == 'SpinRoulade'] = NA
clean.data.reduced$Repetition_count[clean.data.reduced$Gesture_record == 'SpinSomersault'] = NA

```


### Extract relevant variables

To test how different modifiers impact gesture actions, some of the
modifier columns are currently not optimal - some have too much
information, some too little. For example, *Flexion* currently includes
information on all three joints at the same time, while we might not
care so much whether a gesture sees 2 or 5 repetitions rather than the
fact that there is repetition at all. For laterality, we mainly care
whether gestures were done unimanual, bimanual, or bimanual with
alternating movements.

```{r prepare_repertoire_columns, echo = TRUE}

clean.data.reduced$Object_involved <-
  ifelse((clean.data.reduced$Object_contacted == 'None' &
            clean.data.reduced$Object_used == 'None'),
         'None',
         'Yes')

# clean.data.reduced$Object_used <-
#   ifelse((clean.data.reduced$Object_used == 'None'),
#          'None',
#          'Yes')
# 
# clean.data.reduced$Object_contacted <-
#   ifelse((clean.data.reduced$Object_contacted == 'None'),
#          'None',
#          'Yes')

clean.data.reduced$Flexion_elbow <- 
  ifelse(str_detect(clean.data.reduced$Flexion, pattern = "Elbow"), 
         "yes", 
         "no")
clean.data.reduced$Flexion_wrist <- 
  ifelse(str_detect(clean.data.reduced$Flexion, pattern = "Wrist"), 
         "yes", 
         "no")
clean.data.reduced$Flexion_finger <- 
  ifelse(str_detect(clean.data.reduced$Flexion, pattern = "Finger"), 
         "yes", 
         "no")

clean.data.reduced$Repetition <- 
  ifelse(clean.data.reduced$Repetition_count > 0, 
         "yes", 
         "no")
clean.data.reduced$Laterality <- 
  ifelse(clean.data.reduced$Laterality_signaller %in% c("Left", "Right"),
         "unimanual",
         clean.data.reduced$Laterality_signaller)


```

Subsequently, we only select the columns we are actually interested in
when establishing the repertoire. These currently contain:

```{r g_data, echo = T}
g.data <- clean.data.reduced %>% 
  select(
    # gesture action
    Gesture_record,
    # modifiers
    Body_part_signaller,
    Body_part_contact,
    Flexion_wrist,
    Flexion_elbow,
    Orientation,
    Repetition,
    Laterality)

```

## Exlude across gesture actions

Remember, we had three criteria to determine whether any of the
modifiers can be exclude across the board:

1.  Only one option of the modifier is ever used.
2.  The modifier is never applicable.
3.  The modifier is perfectly explained by another modifier (very high
conditional probability).

While the first two are easy to detect (there are simply no data points
or no variation), the last one requires us to calculate all the
conditional probabilities across all modifiers. The function below
achieves this; it takes into account only cases where, in theory, both
variables could co-occur. It has different outputs: first, we'll see the
wide output, that shows that unconditional and conditional probabilities
of the modifiers occurring. Here, we only show the first couple of
lines.

```{r conditional_across}

conditional_across <-
  calculate_prob_of_comb(data = g.data, 
                         modifiers = colnames(g.data)[-1])

kable(conditional_across$symmetrical %>%
        select(
          mod1,
          mod2,
          unconditional.prob,
          conditionalAgB,
          conditionalBgA
        ) %>% filter(unconditional.prob > 0) %>% 
        head(), 
      caption = 'First few cases of modifier combinations and their conditional probabilities',
      format = 'html', 
      row.names = NA,
      align = "c",
      booktabs = T) %>% 
  kable_styling(font_size = 9)

```

Modifiers can be determinate either one way (i.e., one level of a
modifier only ever shows one level of the other, but this is not
reciprocated) or both ways (i.e., same as before, but also vice versa).
For example, in the first case, every time we see that the fingers are
flexed, we also see repetition of the gesture, but sometimes when we see
repetition, the fingers are not flexed. In the second case, finger
flexing and repetition are perfectly explained by each other.

What we see across the dataset are a number of cases of the first kind:
For example, none of the flexion modifiers ever co-occurs with any body
contact or object use.

```{r, echo=TRUE}
kable(conditional_across$one_way_determined %>% 
        filter(str_detect(modifier, 'Flexion')) %>% 
        arrange(modifier) %>% head(10),
      caption = 'Modifiers that have high conditional probability one way', 
      format = 'html', 
      row.names = NA,
      align = "c",
      booktabs = T) %>% 
  kable_styling(font_size = 9)
```

What we do not see are any cases where two modifiers, across all gesture
events, are perfectly aligned and essentially redundant information.
Thus, we cannot exclude any modifiers at this stage.

```{r, echo=TRUE}
kable(conditional_across$two_way_determined %>% 
        arrange(modifier), 
      caption = 'Modifiers that have perfect conditional probability both ways, making them highly deterministic', 
      format = 'html', 
      row.names = NA,
      align = "c",
      booktabs = T) %>% 
  kable_styling(font_size = 9)
```

### Combine modifier levels

Some modifier levels are just very rare and it is unlikely that they create any information in this sample. This is particularly the case if the modifier level only ever occurs as the only level in a gesture action and apart from that is rare. The following table shows how often each modifier level occurs *in a gesture action where more than one option is ever chosen*.

```{r rare_levels}

modifier.check.table <- probability_table(data = g.data, 
                                modifiers = colnames(g.data)[-1]) %>% 
  filter(count > 0 & probability < 1) %>% 
  group_by(modifier, level) %>% 
  summarise(count.option = sum(count)) %>% 
  ungroup() %>% 
  left_join(probability_table(data = g.data, 
                              modifiers = colnames(g.data)[-1]) %>% 
              filter(count > 0) %>% 
              group_by(modifier, level) %>% 
              summarise(count.total = sum(count)) %>% 
              ungroup()) %>% 
  data.frame() %>% 
  suppressMessages()

modifier.check.table %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)


```


What we see is that some of them are truly rare - with as few as `r modifier.check.table$count %>% min()` cases seen for some of them. While those very rare ones would anyways be removed because they fall below the cutoff value in all cases, some other modifier levels might create false morphs simply due to our extreme splitting for two modifiers: *body_part_signaller* and *body_part_contact*. For these, `r modifier.check.table %>% filter(str_detect(modifier, 'Body_part')) %>% filter(count.total <= nrow(g.data)/100) %>% nrow()` occur fewer than 1% of the time. Some of these can easily be combined with other modifier levels, without losing information or the ability to include them for other species or once more data are available. Also, *object involved* and *body part signaller genitals* never really optional - they either occur or they do not, so they are pointless modifiers for the formation of morphs.

To facilitate things, we will combine modifier levels the following way:

-   Body Part Contact: *Fist* becomes *Fingers_Hand*, *BodyChest* and *BodyFront* become part of *Body*, *Bottom* becomes part of *Leg*. We leave *Genitals* alone for now.
-   Body Part Signaller: *BodyChest* and *BodyFront* become part of *Body*, *Fist* and *Knuckles* is combined with *Hand*, *HandFoot* is combined with *Foot*. We leave *Head* alone for now.

```{r g_data_amend, echo = T}

clean.data.reduced$Body_part_contact[clean.data.reduced$Body_part_contact == 'Fist'] = 'Fingers_Hand'
clean.data.reduced$Body_part_contact[clean.data.reduced$Body_part_contact == 'BodyChest'] = 'Body'
clean.data.reduced$Body_part_contact[clean.data.reduced$Body_part_contact == 'BodyFront'] = 'Body'
clean.data.reduced$Body_part_contact[clean.data.reduced$Body_part_contact == 'Bottom'] = 'Leg'

clean.data.reduced$Body_part_signaller[clean.data.reduced$Body_part_signaller == 'Fist'] = 'Hand'
clean.data.reduced$Body_part_signaller[clean.data.reduced$Body_part_signaller == 'Knuckles'] = 'Hand'
clean.data.reduced$Body_part_signaller[clean.data.reduced$Body_part_signaller == 'BodyChest'] = 'Body'
clean.data.reduced$Body_part_signaller[clean.data.reduced$Body_part_signaller == 'BodyFront'] = 'Body'
clean.data.reduced$Body_part_signaller[clean.data.reduced$Body_part_signaller == 'HandFoot'] = 'Foot'


g.data <- clean.data.reduced %>% 
  select(
    # gesture action
    Gesture_record,
    # modifiers
    Body_part_signaller,
    Body_part_contact,
    Flexion_wrist,
    Flexion_elbow,
    Orientation,
    Repetition,
    Laterality)

```

After this, g.data has still `r g.data %>% distinct(.keep_all = TRUE) %>% nrow()` unique gesture action/modifier set combinations. That's probably too many to build morphs from directly, because no analyses would be able to process this given the datasets we have. Therefore, we need reliable ways to reduce the information to a manageable set of morphs.

\newpage

# Analysis

## Create probabilities within gesture actions

Let's calculate the basic probabilities of each modifier level within
each gesture action. Please note that all probabilities are dependent on
the modifier being used and any value being assigned; thus, if we have a
gesture action where *Body_part_signaller* was 4 times *NA*, 2 times
'Leg', and 2 times 'Torso', each of the latter two has a probability of
0.5. The 'probability_table' function creates a table that summarises
for each gesture action and each modifier which level was chosen at what
probability. Probabilities should sum up to one within gesture actions
and modifiers - all chosen body parts within *Beckon* should sum to the
entirety of times any body part could be identified.

```{r prob_table, echo = T}

prob.table <- probability_table(data = g.data, 
                                modifiers = colnames(g.data)[-1])

kable(prob.table %>%
        filter(count > 0) %>% 
        head(6), 
      caption = 'Probability table summarising the variation within each gesture action/modifier level', 
      format = 'html', 
      row.names = NA,
      align = "c",
      booktabs = T) %>% 
  kable_styling(font_size = 9)
```

### Gestures without variation

With this information in hand, we can take a first step: identify those
gesture actions that only ever occur in one specific way, with no
variation in any of the modifiers.

```{r one_Way_gestures}
one_way_gestures <- prob.table %>%
  filter(count > 0) %>% 
  group_by(gesture_action) %>% 
  summarise(mean.prob = mean(probability)) %>%
  ungroup() %>% 
  filter(mean.prob == 1) %>% 
  select(gesture_action) %>% 
  unlist %>% as.vector

print(one_way_gestures)
```

Looking at the list, there are currently `r length(one_way_gestures)`
gesture actions that only ever occur in one particular way. Those amount
to
`r (length(one_way_gestures) / length(unique(prob.table$gesture_action))) * 100`%
of all gesture actions in the dataset.

\newpage

### Gestures with variation

What about the others? Even within those, there are a lot of modifiers
that do not show any variation. Let's first create a data frame that
contains only the gestures actions and modifiers with detectable
variation.

```{r multiway_gestures}
multi.gestures <- prob.table %>% 
  filter(count > 0) %>% 
  filter(!(gesture_action%in%one_way_gestures)) %>% 
  group_by(gesture_action, modifier) %>% 
  summarise(mean.prob = mean(probability), .groups = 'keep') %>% 
  filter(mean.prob != 1) %>% 
  ungroup() %>% 
  right_join(prob.table, by = c('gesture_action', 'modifier')) %>% 
  filter(!is.na(mean.prob)) %>% 
  filter(count > 0) %>% 
  select(-mean.prob)

```

We are left with `r nrow(multi.gestures)` gesture action/ modifier
combinations, for `r length(unique(multi.gestures$gesture_action))`
gesture actions
(`r (length(unique(multi.gestures$gesture_action)) / length(unique(prob.table$gesture_action))) * 100`%
of the total) and `r length(unique(multi.gestures$modifier))` modifiers
(`r (length(unique(multi.gestures$modifier)) / length(unique(prob.table$modifier))) * 100`%
of the total).

It might make sense to build in a cut-off value - we only consider a
gesture action/ modifier level combination relevant if we see it more
than x times. Currently, of the `r nrow(multi.gestures)` gesture
action/modifier combinations,
`r mean(multi.gestures$count <= cutoff_overall) *  100`% occur
`r cutoff_overall` times or less, reducing apparent variability that
might be due to coding errors or rare events. This would leave us with
`r multi.gestures %>% filter(count > cutoff_overall) %>% nrow()` gesture
action/modifier level combinations across
`r multi.gestures %>% distinct(gesture_action) %>% nrow()` gesture
actions.

\newpage

## Cluster Detection Algorithms

The main problem with using the probabilities to narrow down the gesture
action/modifier combinations is that each gesture event can be classed
in multiple categories: if *arm raise* differs by elbow flexion (yes/no)
and by wrist flexion (yes/no), then is a case where the elbow and wrist
are flexed an example of *arm raise - wrist flexed* or *arm raise - elbow flexed*? This would be a real challenge for a repertoire - we
optimally want a solution that assigns each instance exactly one
gesture. We could split it for ways (for the flexion, e.g., yes/yes,
yes/no, no/yes, no/no), but this leaves us with very few cases for many
of the combinations.

A way to solve this is to use clustering algorithms to find
statistically meaningful hidden underlying or 'latent' classes. We could identify those, see if they provide us with clear reproducible rules how to split a gesture action into morphs, and then determine whether the morphs are useful. This approach could potentially
reduce a lot of variation that we as humans cannot meaningfully handle.
The main problem is that the clustering algorithms are often rather
opaque - we do not always understand why the split occurred the way it.
However, we can identify how the different modifier levels fall into
detected clusters and find those modifier levels that have both a very
high probability of occurring in the cluster (hopefully 1) and a very
high specificity to this cluster (they occur in this cluster and this
cluster only). Modifiers that occur at high probability only in all
clusters (probability = 1, specificity = low) are not very informative;
neither are modifiers that have high specificity but low probability.
Thus, we are trying to find those modifiers that occur in all cases of a
cluster, and differentiate that cluster from others.

Computationally, we use Bayesian Latent Class Analysis (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6364555/) to detect latent classes in the categorical data that are the modifiers. LCA is a model-based cluster detection approach (in contrast to, say, k-means, which is heuristic) - the model quantifies the best split of data given a certain number of assumed clusters and gives us a AIC or BIC value that quantifies the likelihood that the clustering correctly describes some underlying cluster. By repeating the process with multiple cluster sizes and comparing AICs/BICs, we can find the cluster solution that describes the data with the smallest amount of error. We make a second assumption, which is that the best solution is one that only has clusters comprised of at least `r cutoff_overall` cases, our cutoff value.

Here is an example, using *ObjectShake*. Using the probabilistic
approach earlier, we found that *ObjectShake* is differentiated by the
body part used (Hand vs Leg), the Laterality (Alternating vs Both vs
unimanual) and whether the gesture was repeated or not. This would
potentially create a rather large number of possible gestures to split
into, which is something we want to avoid.

```{r cluster_single, echo = TRUE, cache = TRUE}

xx.OS = morph_detection_bayes(
  data = g.data,
  modifiers = colnames(g.data)[-1],
  gesture_action = colnames(g.data)[1],
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall)

```

The current best cluster solution contains
`r xx.OS$cluster.info$cluster %>% max()` clusters. These are
best represented by the following modifiers, which have both high
probability of occurring in this cluster (probability = 1) and high
specificity by not occurring in any of the other clusters (specificity
= 0.5).

```{r}
xx.OS$cluster.info %>% 
  filter(probability == 1 & 
           specificity == 1) %>% 
  kable(format = 'html',
        row.names = NA,
        align = "c",
        booktabs = T) %>% 
  kable_styling(font_size = 9)
```

The clusters seem to be build around one modifier: One cluster seems
to contain cases of ObjectShake that are done with two hands, with the
remaining including most that are done with one hand. Using a network
graph, this perception is confirmed.

```{r object_shake_network, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Bipartite network plot of connection between clusters and important modifiers for ObjectShake."}
plot_bipartite(
  prob.table = xx.OS$cluster.info %>% filter(nr.rules == 1),
  select.modifier = "cluster",
  plot.title = 'ObjectShake',
  cutoff = cutoff_overall,
  threshold = 0
)
```

This approach reduces a lot of the variation compared to the previous
approach: for example, while we assumed that the body part of the
signaller might matter, it turns out that only 2% of all cases of this
gesture are done with the foot, so the dimension reduction algorithm
gets rid of this dimension. The same happens to the 'alternating'
laterality. The hierarchical way of splitting the gesture cases means
that each gesture case is assigned to exactly one category while the
number of different clusters is held to a minimum.

```{r object_shake_tree, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Decision tree explaining the clusters and important modifiers for ObjectShake."}

rpart.plot(
      xx.OS$tree,
      type = 4,
      fallen.leaves = FALSE,
      cex = 0.5,
      extra = 0,
      box.palette = "Greys"
    ) %>%
      suppressWarnings()
```

The clustering approach often leads to a relatively large number of
clusters, but it is hard to establish which of these morphs is
potentially an independent source of information and which of them are
potentially just random variation that we introduce by having a detailed
coding scheme. While we try to exclude Meaning as a variable of interest
as much as possible in this analysis, it is worth keeping it in mind
because it will ultimately be the variable that decides whether two
morphs are meaningfully distinct. There are two ways of finding out
which of the morphs are important: first, we can establish which
modifiers could potentially contain relevant information by testing
whether knowledge of the modifier reduces uncertainty about the meaning
of the gesture action very broadly. We would do that by testing whether
the entropy/uncertainty about which Goal the gesture was assigned to is
reduced if the modifier is known (vs randomised). We could then
calculate clusters based only on modifiers for which we have an
indication that they contain relevant information about Meaning.
Alternatively, we use the same approach, but we first determine the
clusters using the maximum set of modifiers, and then test whether any
of the morphs differ from expected with regard to their meaning. We will
present both approaches below for *ObjectShake*.

```{r OS_modifier_entropy}
# use modifier_entropy function to detect which modifiers give us any information about the meaning of the gesture action
entropy.OS = modifier_entropy(
  data = g.data,
  modifiers = colnames(g.data)[-1],
  gesture_action = colnames(g.data)[1],
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall,
  target = clean.data.reduced$Goal)

entropy.OS %>% 
  select(modifier,
         level,
         count,
         entropy.observed,
         entropy.expected,
         pvalue.entropy) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

```{r OS_morph_entropy}
# run the same entropy approach but for the clusters - does any of them reduce uncertainty?
entropy.OS.cluster = modifier_entropy(
  data = cbind(xx.OS$full.data,
               GA = rep('ObjectShake', nrow(xx.OS$full.data))),
  modifiers = 'cluster',
  gesture_action = 'GA',
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall,
  target =
    clean.data.reduced$Goal[clean.data.reduced$Gesture_record == 'ObjectShake']
)

entropy.OS.cluster %>%
  select(modifier,
         level,
         count,
         entropy.observed,
         entropy.expected,
         pvalue.entropy) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

## Cluster Detection

What we will do next is essentially to run the cluster algorithm for all
gesture actions, compare them automatically with the probability based
solutions as much as possible and detect the ones for which we need to
check manually which solution would be appropriate. We consider the two
approaches to provide the same solution if the defining modifiers of the
clusters are the same that show variation with the probabilistic
approach, or if both indicate that there is only one cluster. Sometimes
clusters are not based on high probability and specificity of one
modifier, but a combination of two modifiers; where no one-modifier
solution exists, we will provide this information.

**Notes:**

-   The code to run this in parallel and get all the information out is still quite messy and involves too many steps, need to sort this out better.

-   This currently takes about 2h to run on 8 cores


### Run cluster analysis for all gesture actions

```{r, include=FALSE}

# parallelise
mycluster <- makeCluster(16, type = "PSOCK")
# export the relevant information to each core
clusterExport(
  cl = mycluster,
  c(
    "g.data",
    "cutoff_overall",
    "plot_bipartite",
    "probability_table",
    "clean.data.reduced",
    "calculate_prob_of_comb",
    "compute_possible_combs",
    "saveRDS"
  ),
  envir = environment()
)
registerDoParallel(mycluster)
suppressMessages(clusterCall(mycluster, function() library(dplyr)))
suppressMessages(clusterCall(mycluster, function() library(stringr)))
suppressMessages(clusterCall(mycluster, function() library(tidyr)))
suppressMessages(clusterCall(mycluster, function() library(tidytext)))
suppressMessages(clusterCall(mycluster, function() library(tidyfast)))
suppressMessages(clusterCall(mycluster, function() library(tidymodels)))
suppressMessages(clusterCall(mycluster, function() library(embed)))
suppressMessages(clusterCall(mycluster, function() library(plotly)))
suppressMessages(clusterCall(mycluster, function() library(ggplot2)))
suppressMessages(clusterCall(mycluster, function() library(purrr)))
suppressMessages(clusterCall(mycluster, function() library(cluster)))
suppressMessages(clusterCall(mycluster, function() library(BayesLCA)))
suppressMessages(clusterCall(mycluster, function() library(arrangements)))
suppressMessages(clusterCall(mycluster, function() library(Rfast)))
suppressMessages(clusterCall(mycluster, function() library(ggraph)))
suppressMessages(clusterCall(mycluster, function() library(igraph)))
suppressMessages(clusterCall(mycluster, function() library(reshape2)))

```


```{r cluster_solutions, echo=TRUE, warning=FALSE, cache=TRUE, message=FALSE, include=TRUE}

gesture_clusters <- 
  parLapply(mycluster,# go through each gesture action independently
    X = unique(g.data$Gesture_record),
    function(y) {
      devtools::load_all("~/GitHub/Gestures/R package/wildminds/R/")   
      library(tidymodels)
      print(y)
      # set action
      action <- y
      # set cutoff
      cutoff.value <- cutoff_overall
      # select gesture action data
      ga.data <- g.data %>%
        filter(Gesture_record == action)
      # store additional info
      ga.identifier <- clean.data.reduced %>%
        filter(Gesture_record == action) %>%
        select(Social_unit, 
               Species,
               Coder, 
               Signaller, 
               Goal,
               Part_sequence)
      
      # make lca of modifiers
      ga.lca <- 
        morph_detection_bayes(
          data = ga.data,
          modifiers = colnames(ga.data)[-1],
          gesture_action = colnames(ga.data)[1],
          plot.action = action,
          cutoff = cutoff.value
        )
      
      return(ga.lca)
    }
  )

stopCluster(mycluster)

names(gesture_clusters) <- unique(g.data$Gesture_record)
```



### Extract useful information

```{r, include=FALSE}
# calculate basic probabilities
prob.table <- probability_table(data = g.data,
                                modifiers = colnames(g.data)[-1]) %>%
  filter(count > 0)


# run parallel loop

# parallelise
mycluster <- makeCluster(16, type = "PSOCK")
# export the relevant information to each core
clusterExport(
  cl = mycluster,
  c(
    "g.data",
    "prob.table",
    "cutoff_overall",
    "plot_bipartite",
    "probability_table",
    "clean.data.reduced",
    "calculate_prob_of_comb",
    "compute_possible_combs",
    "saveRDS",
    "gesture_clusters"
  ),
  envir = environment()
)
registerDoParallel(mycluster)
suppressMessages(clusterCall(mycluster, function()
  library(dplyr)))
suppressMessages(clusterCall(mycluster, function()
  library(stringr)))
suppressMessages(clusterCall(mycluster, function()
  library(tidyr)))
suppressMessages(clusterCall(mycluster, function()
  library(tidytext)))
suppressMessages(clusterCall(mycluster, function()
  library(tidyfast)))
suppressMessages(clusterCall(mycluster, function()
  library(tidymodels)))
suppressMessages(clusterCall(mycluster, function()
  library(embed)))
suppressMessages(clusterCall(mycluster, function()
  library(plotly)))
suppressMessages(clusterCall(mycluster, function()
  library(ggplot2)))
suppressMessages(clusterCall(mycluster, function()
  library(purrr)))
suppressMessages(clusterCall(mycluster, function()
  library(arrangements)))
suppressMessages(clusterCall(mycluster, function()
  library(Rfast)))
suppressMessages(clusterCall(mycluster, function()
  library(ggraph)))
suppressMessages(clusterCall(mycluster, function()
  library(igraph)))
suppressMessages(clusterCall(mycluster, function()
  library(reshape2)))

```


```{r cluster_solutions_summary, echo=TRUE, warning=FALSE, cache=TRUE, message=FALSE, include=TRUE}

cluster_solutions <-
  parLapply(mycluster, # go through each gesture action independently
            gesture_clusters,
            function(y) {
              devtools::load_all("~/GitHub/Gestures/R package/wildminds/R/")
              print(y$gesture.action)
              ga.lca <- y
              # set action
              action <- ga.lca$gesture.action
              # set cutoff
              cutoff.value <- cutoff_overall
              # select gesture action data
              ga.data <- g.data %>%
                filter(Gesture_record == action)
              # store additional info
              ga.identifier <- clean.data.reduced %>%
                filter(Gesture_record == action) %>%
                select(Social_unit,
                       Species,
                       Coder,
                       Signaller,
                       Goal,
                       Part_sequence)
              
              # make a list for summary information
              action.summary <- list()
              action.summary$gesture.action <- action
              action.summary$cutoff <- cutoff.value
              action.summary$count <- nrow(ga.data)
              
              # make probability table for this action
              action.summary$probability.table <-
                prob.table %>%
                filter(gesture_action == action) %>%
                filter(count > 0)
              # calculate all modifiers in this gesture action that have variation
              action.summary$all.variation <-
                action.summary$probability.table %>%
                filter(count > 0) %>%
                # indentify modifier with more than one level
                group_by(modifier) %>%
                summarise(mean.prob = mean(probability),
                          .groups = "keep") %>%
                filter(mean.prob != 1) %>%
                ungroup() %>%
                # add info to table
                right_join(action.summary$probability.table,
                           by = c("modifier")) %>%
                filter(!is.na(mean.prob)) %>%
                select(-mean.prob) %>%
                # make modifier_level variable
                unite(modifier_level,
                      modifier,
                      level, sep = ".") %>%
                select(modifier_level) %>%
                unlist(use.names = FALSE)
              
              # if no modifier has enough variation, add NA
              if (action.summary$probability.table %>%
                  filter(count > cutoff.value) %>%
                  nrow() == 0) {
                action.summary$all.variation.cutoff <- NA
              }
              
              # if at least one modifier has variation, check after accounting for cutoff
              if (action.summary$probability.table %>%
                  filter(count > cutoff.value) %>%
                  nrow() > 0) {
                action.summary$all.variation.cutoff <-
                  action.summary$probability.table %>%
                  filter(count > cutoff.value) %>%
                  # indentify modifier with more than one level
                  group_by(modifier) %>%
                  summarise(mean.prob = n(),
                            .groups = "keep") %>%
                  filter(mean.prob != 1) %>%
                  ungroup() %>%
                  # add info to table
                  right_join(action.summary$probability.table,
                             by = c("modifier")) %>%
                  filter(!is.na(mean.prob)) %>%
                  select(-mean.prob) %>%
                  # make modifier_level variable
                  unite(modifier_level, modifier, level, sep = ".") %>%
                  select(modifier_level) %>%
                  unlist(use.names = FALSE)
              }
              
              # calculate modifier levels that are one-way deterministic for each other
              action.summary$one.way.deterministic <-
                calculate_prob_of_comb(
                  data = ga.data,
                  modifiers = unique(
                    action.summary$probability.table %>%
                      filter(count > 0) %>%
                      select(modifier) %>%
                      unlist()
                  )
                )$long %>%
                filter(conditional.prob > 0.95) %>%
                select(mod1,
                       mod2,
                       observed,
                       unconditional.prob,
                       conditional.prob)
              # calculate modifier levels that are two-way deterministic for each other
              action.summary$two.way.deterministic <-
                conditional_modifiers(
                  data = ga.data,
                  modifiers = unique(
                    action.summary$probability.table %>%
                      filter(probability > 0) %>%
                      select(modifier) %>%
                      unlist()
                  )
                )
              
              # entropy development with sample size
              action.summary$entropy.development <-
                entropy_development_modifiers(
                  data = ga.data,
                  modifiers = colnames(ga.data)[-1],
                  gesture_action = action
                )
              
              
              # Check Entropy of goals
              ga.entropy.cluster = modifier_entropy(
                data = ga.lca$full.data %>%
                  mutate(GA = action),
                modifiers = 'cluster',
                gesture_action = 'GA',
                plot.action = action,
                cutoff = cutoff_overall,
                target = ga.identifier$Goal
              )
              
              # Check entropy of modifiers
              
              ga.entropy.modifiers = modifier_entropy(
                data = ga.data,
                modifiers = colnames(ga.data)[-1],
                gesture_action = colnames(ga.data)[1],
                plot.action = action,
                cutoff = cutoff_overall,
                target = ga.identifier$Goal
              )
              
              ### check group patterns
              ga.groups <-
                list(count =
                       table(
                         ga.identifier$Social_unit,
                         ga.lca$full.data$cluster,
                         dnn = c("Group", "Cluster")
                       ))
              
              ga.groups$probability <-
                t(t(ga.groups$count) /
                    colSums(ga.groups$count))
              
              
              ### Check species patterns
              ga.species <-
                list(count =
                       table(
                         ga.identifier$Species,
                         ga.lca$full.data$cluster,
                         dnn = c("Species", "Cluster")
                       ))
              
              ga.species$probability <-
                t(t(ga.species$count) /
                    colSums(ga.species$count))
              
              ### Check coder patterns
              ga.coder <- list(count =
                                 table(
                                   ga.identifier$Coder,
                                   ga.lca$full.data$cluster,
                                   dnn = c("Coder", "Cluster")
                                 ))
              ga.coder$probability <- t(t(ga.coder$count) /
                                          colSums(ga.coder$count))
              
              
              ### Check Goal patterns
              ga.goals <- list(count =
                                 table(
                                   ga.identifier$Goal,
                                   ga.lca$full.data$cluster,
                                   dnn = c("Goal", "Cluster")
                                 ))
              ga.goals$probability <-
                t(t(ga.goals$count) /
                    colSums(ga.goals$count))
              
              
              ### if there is no cluster, return NAs
              if (ga.lca$distinction.info$nr.clusters == 1) {
                action.summary$cluster.solution.number <- 1
                action.summary$cluster.solution.options <- NA
                action.summary$cluster.solution <- NA
                action.summary$cluster.solution.important <- NA
                action.summary$cluster.solution.network <- NA
                action.summary$cluster.solution.tree <- NA
                action.summary$cluster.solution.tree.importance <-
                  NA
                action.summary$group.distribution <- ga.groups
                action.summary$coder.distribution <- ga.coder
                action.summary$goal.distribution <- ga.goals
                action.summary$full.data <- cbind(ga.data,
                                                  ga.identifier,
                                                  cluster = ga.lca$full.data$cluster)
                action.summary$morph.summary <- NA
                action.summary$entropy.modifiers <- NA
                action.summary$entropy.clusters <- NA
              }
              
              ### If clusters were detected, extract all possible info
              if (ga.lca$distinction.info$nr.clusters > 1) {
                # how many morphs?
                action.summary$cluster.solution.number <-
                  max(ga.lca$cluster.info$cluster %>%
                        as.numeric())
                # how many morphs could have been established?
                action.summary$cluster.solution.options <-
                  ga.lca$solutions
                
                # save individual modifier probability and specificity for morphs
                action.summary$cluster.info <-
                  ga.lca$cluster.info %>%
                  filter(probability > 0)
                
                # save modifiers and combinations that are highly predictive of morphs
                action.summary$cluster.solution.important <-
                  action.summary$cluster.info %>%
                  filter(probability == 1 & specificity == 1) %>%
                  select(modifier) %>%
                  unlist(use.names = FALSE) %>%
                  as.character()
                
                # make lca plot
                action.summary$cluster.solution.network <-
                  plot_bipartite(
                    prob.table = ga.lca$cluster.info %>% filter(nr.rules == 1),
                    select.modifier = "cluster",
                    plot.title = action,
                    cutoff = 0
                  )
                
                # make decision tree plot
                # get variable importance from decision tree
                action.summary$cluster.solution.tree.importance <-
                  ga.lca$tree.var.importance
                
                # save the different distributions by Goal, group, species etc
                action.summary$group.distribution <- ga.groups
                action.summary$species.distribution <- ga.species
                action.summary$coder.distribution <- ga.coder
                action.summary$goal.distribution <- ga.goals
                
                # save full dataset for later use, including addition info
                action.summary$full.data <-
                  cbind(ga.data, ga.identifier, cluster = ga.lca$full.data$cluster)
                
                # check rules for morphs
                
                summary_morphs <- list(
                  ## check which morphs significantly reduced entropy
                  ent.goals = ga.entropy.cluster %>%
                    filter(pvalue.entropy <= 0.05) %>%
                    select(level) %>%
                    unlist(F, F) %>%
                    str_replace('cluster.', ''),
                  ## check which morphs were group specific
                  distinct.group =
                    colnames(ga.groups$count)[ga.groups$probability %>%
                                                apply(2, max) ==
                                                1],
                  ## check which morphs were Goal specific
                  distinct.goal =
                    colnames(ga.goals$count)[ga.goals$probability %>%
                                               apply(2, max) ==
                                               1],
                  ## check which morphs were explained by one modifier level
                  distinct.probability.specificity =
                    ga.lca$cluster.info %>%
                    filter(probability == 1 &
                             specificity == 1) %>%
                    select(cluster) %>%
                    unlist(F, F) %>%
                    as.character() %>%
                    unique(),
                  # cluster count
                  cluster.count =
                    ga.lca$cluster.info %>%
                    distinct(cluster, .keep_all = TRUE) %>%
                    pull(count.cluster)
                )
                
                ## make a summary of the morphs
                morph_sum <- data.frame(cluster =
                                          sort(ga.lca$full.data$cluster %>%
                                                 unique())) %>%
                  mutate(
                    entropy.goal =
                      as.numeric(cluster %in%
                                   summary_morphs$ent.goals),
                    distinct.group =
                      as.numeric(cluster %in%
                                   summary_morphs$distinct.group),
                    distinct.goal =
                      as.numeric(cluster %in%
                                   summary_morphs$distinct.goal)
                  )
                
                # by which of those rules would the morph be considered 'clear'
                morph_sum$rules <-
                  sapply(1:nrow(morph_sum), function(x) {
                    xx <- morph_sum[x, -1]
                    return(paste(colnames(xx)[which(xx == 1)], collapse = ', '))
                  })
                
                morph_sum$gesture_action <- action
                
                # add to action.summary
                action.summary$morph.summary <- morph_sum
                action.summary$entropy.clusters <-
                  ga.entropy.cluster
                action.summary$entropy.modifiers <-
                  ga.entropy.modifiers
              }
              
              # save each run so I don't have to start over every time
              return(action.summary)
            })

stopCluster(mycluster)
```


### Extract from cluster summary

```{r extract_from_summary}
# name elements of list
names(cluster_solutions) <- 
  sapply(cluster_solutions, function(y) y$gesture.action)

# transpose to make more easily accessible
cluster_transposed <- purrr::transpose(cluster_solutions)

cluster_solution_summary <-
  data.frame(
    gesture.action = 
      unlist(cluster_transposed$gesture.action,
             use.names = FALSE),
    count = 
      unlist(cluster_transposed$count,
             use.names = FALSE),
    variation.number = 
      sapply(cluster_transposed$all.variation.cutoff, length),
    cluster.number = 
      unlist(cluster_transposed$cluster.solution.number,
             use.names = FALSE
      ),
    variation.modifiers = 
      sapply(cluster_transposed$all.variation.cutoff, function(x) {
        unlist(x) %>%
          str_split("\\.") %>%
          unlist() %>%
          unique() %>%
          intersect(colnames(g.data)) %>%
          sort() %>%
          paste(collapse = ", ")
      }),
    cluster.modifiers = sapply(
      cluster_transposed$cluster.solution.important, function(x) {
        if (length(x) == 0) {
          return(paste(""))
        }
        x %>%
          unlist() %>%
          str_split("\\.") %>%
          unlist() %>%
          unique() %>%
          intersect(colnames(g.data)) %>%
          sort() %>%
          paste(collapse = ", ")
      }
    )
  )
cluster_solution_summary$variation.number <- ifelse(
  cluster_solution_summary$variation.number == 0,
  1,
  cluster_solution_summary$variation.number
)

distinction.infos <- purrr::transpose(gesture_clusters)$distinction.info

distinction.infos[is.na(distinction.infos)] <- 
  rep(list(data.frame(nr.clusters = 1, 
                      nr.clusters.distinct = 1, 
                      nearest.neighbours = 3)), 
      length(distinction.infos[is.na(distinction.infos)]))

distinction.infos <- distinction.infos %>% 
  bind_rows() %>% 
  mutate(gesture_action = sapply(gesture_clusters, function(y) y$gesture.action)) %>% 
  select(gesture_action, nr.clusters, nr.clusters.distinct) %>% 
  mutate(nr.clusters.unclear = nr.clusters - nr.clusters.distinct)


```

In total, if we go purely with the cluster solution for each gesture
action, we would end up with a repertoire of in total
`r distinction.infos$nr.clusters %>% sum()` morphs, ranging
between 1 and `r distinction.infos$nr.clusters %>% max()` morphs
per gesture action. For most gesture actions, the morphs could be identified using a clear set of rules - for
`r distinction.infos %>% filter(nr.clusters == nr.clusters.distinct) %>% pull(gesture_action) %>% unique() %>% length()` of `r nrow(cluster_solution_summary)` gesture actions, all morphs are clearly defined. The morphs are distributed the following way within the gesture actions:

```{r}
sapply(purrr::transpose(gesture_clusters)$full.data, function(x) max(x$cluster, na.rm = T)) %>% 
  unlist(F,F) %>% 
  table() %>%  
  t() %>%  
  data.frame() %>% 
  select(-Var1) %>% 
  rename('Number_of_moprhs' = '.',
         'Count' = 'Freq') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T) %>% 
  kable_styling(font_size = 9)
```

### Split Rules

If we look at the importance of different modifiers from the random
forest approach, get the following picture for those gesture actions
where splits occurred:

```{r split_importance}
split_importance <- 
  data.frame(variable = 
               cluster_transposed$cluster.solution.tree.importance[
                 sapply(
                   sapply(
                     cluster_transposed$cluster.solution.tree.importance, 
                     is.na), 
                   sum) != 1] %>% 
               sapply(names) %>% 
               unlist() %>% 
               unique() %>% 
               sort()
  )


for(i in seq_along(cluster_transposed$cluster.solution.tree.importance)){
  split_importance <- 
    split_importance %>% 
    left_join(cluster_transposed$cluster.solution.tree.importance[[i]] %>% 
                data.frame(check.names = T) %>% 
                rownames_to_column(var = "variable") %>% 
                rename('importance' = '.') %>% 
                mutate(importance = importance/max(importance))) %>% 
    data.frame() %>% 
    suppressMessages()
  colnames(split_importance)[ncol(split_importance)] = names(cluster_transposed$cluster.solution.tree.importance)[i]
}

split_importance[is.na(split_importance)] = 0

split_importance %>% 
  column_to_rownames('variable') %>% 
  t() %>%
  data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  arrange(variable) %>% 
  column_to_rownames('variable') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

If we plot the average impact of each modifier in gesture actions where
they occur (standardising the impact of all modifiers within gesture
actions by dividing by the sum of all of them, then taking the mean
across all non-NA occurrences of that modifier), we see that there are
clear differences in the importance of modifiers: body part contacted
and laterality seem to lead to clear splits across the gesture actions
in which they occur, while object involved barely matters (mainly
because the gesture actions are already split by object involved), and
Flexion has little impact.

```{r split_importance_plot, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Importance of different modifiers based on random forest assignment."}


xx <- split_importance %>%
  column_to_rownames('variable') %>%
  t() %>%
  data.frame() %>%
  rownames_to_column(var = "variable") %>%
  arrange(variable) %>%
  column_to_rownames('variable')

xx <- xx / rowSums(xx, na.rm = T)

colMeans(xx, na.rm = T) %>%
  data.frame() %>%
  rownames_to_column('modifier') %>%
  rename('Mean_Impact' = '.') %>%
  ggplot(aes(modifier, Mean_Impact)) +
  geom_segment(aes(
    x = modifier,
    xend = modifier,
    y = 0,
    yend = Mean_Impact
  ), color = "grey") +
  geom_point(color = "orange", size = 4) +
  theme_light() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(
      angle = 45,
      vjust = 0.5,
      hjust = 0.2
    )
  ) +
  xlab("Modifier") +
  ylab("Mean Impact in Decision Tree")

```

We see that the importance of the modifiers differs drastically - especially the Flexion variables have little impact. We can also confirm this by checking the entropy reduction based on modifiers - across gesture actions, how many times did knowing the level of a modifier make us more certain about the meaning of the signal?

```{r importance_entropy}
entro <- cluster_transposed$entropy.modifiers
entro.names <- names(cluster_transposed$entropy.modifiers)
entro.names <- entro.names[sapply(entro, length) != 1]
entro <- entro[sapply(entro, length) != 1]
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(gesture_action = entro.names[x]))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(modifier = as.character(modifier)))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(level = as.character(level)))
entro <- entro %>%
  bind_rows() %>%
  filter(pvalue.entropy <= 0.05) %>%
  mutate(level = as.character(level)) %>%
  separate(level,
           into = c('mod', 'lev'),
           sep = '\\.',
           remove = FALSE) %>%
  distinct(gesture_action, mod, .keep_all = T)

entro %>% 
  select('gesture_action','mod') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

Again, we see that there are some modifiers (*Repetition*, *Orientation*, *Flexion*) that only reduce uncertainty for a small number of gesture actions (2 - 4), while *Laterality* and the two body part variables seem to reduce entropy across a range of gesture actions. Only `r entro %>% bind_rows() %>% filter(pvalue.entropy <= 0.05) %>% pull('gesture_action') %>% unique() %>% length()` out of `r clean.data.reduced$Gesture_record %>% unique() %>% length` gesture actions have any modifier that reduces uncertainty at all.

Are there any modifier levels that never do anything?

```{r}
entro <- cluster_transposed$entropy.modifiers
entro.names <- names(cluster_transposed$entropy.modifiers)
entro.names <- entro.names[sapply(entro, length) != 1]
entro <- entro[sapply(entro, length) != 1]
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(gesture_action = entro.names[x]))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(modifier = as.character(modifier)))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(level = as.character(level)))
entro <- entro %>% 
  bind_rows() %>% 
  mutate(sign = as.numeric(pvalue.entropy <= 0.05)) %>% 
  mutate(level = as.character(level)) %>% 
  separate(level, 
           into = c('mod', 'lev'), 
           sep = '\\.', 
           remove = FALSE) %>% 
  group_by(mod, lev) %>% 
  summarise(significance = sum(sign),
            count = sum(count)) %>% 
  data.frame()


entro %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```


## Morphs to keep

The most important rule for morphs should be that within each gesture action, each morph should be defined by one modifier or modifier combination that allows us to assign any case to one morph and one morph only. Here, we check for how many of the morphs this description fits.

```{r}

# get the cluster info tables
cluster_infos <- purrr::transpose(gesture_clusters)$cluster.info
# some gesture actions only have one cluster
gesture_actions_with_one_cluster <- purrr::transpose(gesture_clusters)$gesture.action[
  sapply(cluster_infos, 
         length) == 1] %>% 
  unlist()
#remove gesture actions with only one cluster
cluster_infos <- cluster_infos[sapply(cluster_infos, length) != 1]  
# make table
clear_morphs <- do.call(rbind, cluster_infos) %>% 
  group_by(gesture_action, cluster) %>% 
  summarise(count = max(count.cluster)) %>% 
  ungroup() %>% 
  arrange(gesture_action, cluster) %>% 
  left_join(
    do.call(rbind, cluster_infos)  %>% 
      filter(probability == 1 & specificity == 1) %>% 
      select(gesture_action, cluster) %>% 
      distinct(.keep_all = TRUE) %>%
      mutate(clear.rule = 1)
  ) %>% 
  replace_na(list('clear.rule' = 0))

clear_morphs %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)

```

When we look at the table, we see that only `r clear_morphs %>% filter(clear.rule == 0) %>% nrow()` out of `r nrow(clear_morphs)` morphs are unspecified. In many cases, those are just 'all other' clusters - a category where the clustering algorithm puts combinations that do not fall neatly into any of the other groups. However, for some gesture actions, the situation is more difficult, and the majority of morphs are not defined by one clear rule. One thing to check what to do with these morphs is to check whether there are modifiers and modifier combinations within those gesture actions that could be removed to facilitate the detection of clear patterns (e.g., using the conditionality between modifiers or the entropy approach). A second approach would be to determine whether, despite their not being any modifiers or combinations that perfectly explain a morph, there might be some either/or rules - for example, if a morph is defined perfectly by the signaller using either their hands or their knuckles, and neither of those two ever occurs in any other context, we can still build a replicable rule out of that. Let's check that last point for some of the morphs that were not perfectly specified.

```{r}

additional.rules <- additional_rules(clus_sol = gesture_clusters, 
                                     morphs_nonspec = clear_morphs %>% filter(clear.rule == 0)) 

additional.rules %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

There are some additional rules in this - currently, `r additional.rules %>% distinct(gesture_action, cluster) %>% nrow()` additional morphs can be specified this way, usually because there are some rare cases that are classed together because most of the modifiers are otherwise the same (for example, *Body Part Signaller* with Fingers and Knuckles are often classed together). That would leave `r nrow(clear_morphs %>% filter(clear.rule == 0)) - additional.rules %>% distinct(gesture_action, cluster) %>% nrow()` for which no clear pattern is currently available.

### Final Morph Table

What remains from here would be to make a giant table that has the rules for each morph for all the modifiers, so new data could be classified accordingly. That should be achieved by the following code:

```{r morph_rules}

# create data frame that has each morph, their count, and the possible modifiers
morph_rules <- cluster_infos %>%
  bind_rows() %>%
  group_by(gesture_action, cluster) %>%
  summarise(count = max(count.cluster)) %>%
  ungroup() %>%
  arrange(gesture_action, cluster) %>%
  mutate(
    Body_part_signaller = NA,
    Body_part_contact = NA,
    Flexion_wrist = NA,
    Flexion_elbow = NA,
    Orientation = NA,
    Repetition = NA,
    Laterality = NA,
    rule_complexity = 0,
    to_check = 0
  ) %>%
  suppressMessages()

# go through every morph, check whether they are determined by anything
for (i in seq_along(morph_rules$gesture_action)) {
  # select only modifier levels with perfect probability/specificity
  mods <- cluster_infos %>%
    bind_rows() %>%
    filter(
      gesture_action == morph_rules$gesture_action[i] &
        cluster == morph_rules$cluster[i] &
        probability == 1 &
        specificity == 1
    )
  
  # if none exist check additional rules
  if (nrow(mods) == 0) {
    mods <- additional.rules %>%
      filter(
        gesture_action == morph_rules$gesture_action[i] &
          cluster == morph_rules$cluster[i] &
          specificity == 1
      )
  }
  
  # if something exists now, add it
  if (nrow(mods) > 0) {
    # take only simplest rule
    mods <- mods %>%
      filter(nr.rules == min(nr.rules))
    
    # extract info from 'modifier' column
    mod_levels <-
      str_split(str_split(mods$modifier, pattern = ':') %>% unlist()
                ,
                pattern = '\\.')
    
    # add information to table (can have multiple rules)
    for (j in 1:length(mod_levels)) {
      morph_rules[i, mod_levels[[j]][1]] =
        paste(morph_rules[i, mod_levels[[j]][1]],
              mod_levels[[j]][2], sep = ', ')
    }
    morph_rules$rule_complexity[i] = mods$nr.rules %>%
      min()
  }
  
  if (nrow(mods) == 0) {
    morph_rules$to_check[i] = 1
    morph_rules$rule_complexity[i] = 0
  }
  
}

# go through each modifier and remove double-bookings and weird NAs
modifiers = c(
  'Body_part_signaller',
  'Body_part_contact',
  'Flexion_wrist',
  'Flexion_elbow',
  'Orientation',
  'Repetition',
  'Laterality'
)

for (i in modifiers) {
  morph_rules[, i] =
    sapply(morph_rules[, i] %>%
             unlist(), function(x) {
               if (is.na(x)) {
                 return(NA)
               }
               str_split(x, pattern = ', ') %>%
                 unlist(F, F) %>%
                 unique() %>%
                 setdiff('NA') %>%
                 str_c(collapse = '|')
             }) %>% unlist(F, F)
  
}

# add all gesture actions that had only 1 morph or were removed throughout the pipeline
morph_rules_added <-
  clean.data %>%
  group_by(Gesture_record) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  filter(!(Gesture_record %in% morph_rules$gesture_action)) %>%
  rename('gesture_action' = 'Gesture_record') %>%
  mutate(
    cluster = 1,
    Body_part_signaller = NA,
    Body_part_contact = NA,
    Flexion_wrist = NA,
    Flexion_elbow = NA,
    Orientation = NA,
    Repetition = NA,
    Laterality = NA,
    rule_complexity = 0,
    to_check = 0
  )

morph_rules <- bind_rows(morph_rules,
                         morph_rules_added) %>%
  arrange(gesture_action,
          cluster) %>% 
  unite(morph_name, gesture_action, cluster, sep = '.', remove = FALSE)


```

This table has the following arguments: the gesture action, the cluster, the morph name, the count, one column for each modifier (where NA means that this modifier can be discarded, and otherwise the level is reported, with multiple levels split by '|' to express the logical 'OR'), the rule complexity (how many modifiers are involved in identifying the morph), and whether the morph needs checking because no rule could be established.

We can also add information about the groups and goals. We will only add the three most frequent goals.

```{r}

morph_rules$groups <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$group.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        pull(Group) %>% 
        as.character() %>% 
        sort() %>% 
        str_c(collapse = ',')
    }else {
      return(NA)
    }
  })

morph_rules$nr.groups <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$group.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        nrow()
    }else {
      return(NA)
    }
  })


morph_rules$goals <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$goal.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        arrange(desc(Freq)) %>% 
        head(3) %>% 
        pull(Goal) %>% 
        as.character() %>% 
        str_c(collapse = ',')
    }else {
      return(NA)
    }
  })

morph_rules$nr.goals <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$goal.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        nrow()
    }else {
      return(NA)
    }
  })


```


```{r}
morph_rules %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 10)
```


What we can also see again from this table is the distribution of modifiers in establishing morphs - overall, *Body Part Signaller* was relevant in `r morph_rules %>% filter(!is.na(Body_part_signaller)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Body Part Contact* was relevant in `r morph_rules %>% filter(!is.na(Body_part_contact)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Flexion Wrist* was relevant in `r morph_rules %>% filter(!is.na(Flexion_wrist)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Flexion Elbow* was relevant in `r morph_rules %>% filter(!is.na(Flexion_elbow)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Orientation* was relevant in `r morph_rules %>% filter(!is.na(Orientation)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Laterality* was relevant in `r morph_rules %>% filter(!is.na(Laterality)) %>% distinct(gesture_action) %>% nrow()` gesture actions, and *Repetition* was relevant in `r morph_rules %>% filter(!is.na(Repetition)) %>% distinct(gesture_action) %>% nrow()` gesture actions. In terms of complexity of the morph rules (how many modifiers are needed to establish them), here's a little table.


```{r}

morph_rules$rule_complexity %>% 
  table() %>% 
  data.frame() %>% 
  kable(format = 'html',
        col.names = c('Number of Modifiers', 'Frequency'),
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 10) 

```



\newpage

# Validation

## Morphs of interest

We can determine whether Morphs are an interesting concept by applying some very
basic rules. For examples, let's assume that morphs are useful particles
of communication if they are unique to one group ('distinct.group'), one meaning ('distinct.goal'), or
if they improve our uncertainty about the meaning of the gesture action
(reduced entropy; 'entropy.goal'). These were calculated above, and we can now extract
the morphs that fulfil either of these conditions.

```{r morph_sum}
morphs <- cluster_transposed$morph.summary
morphs <- morphs[sapply(morphs, length) != 1]

morphs <- bind_rows(morphs) %>% 
  mutate_if(is.factor, as.character) %>% 
  mutate_if(is.numeric, as.character)
morphs_unique <- 
  data.frame(cluster = 1, 
             entropy.goal = 1,
             distinct.group = 1, 
             distinct.goal = 1,
             rules = 'onlyMorph',
             gesture_action = names(
               cluster_transposed$morph.summary)[
                 sapply(cluster_transposed$morph.summary, length) == 1]) %>% 
  mutate_if(is.numeric, as.character)

morphs <- bind_rows(morphs, morphs_unique)
morphs_with_clear_use <- morphs %>% 
  filter(rules != '')
morphs_without_clear_use <- morphs %>% 
  filter(rules == '')

morphs_with_clear_use %>% 
  select(gesture_action, cluster, rules) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

For the following `r setdiff(morphs_with_clear_use$gesture_action, morphs_without_clear_use$gesture_action) %>% length()` gesture actions, all morphs have clear rules:

```{r}
setdiff(morphs_with_clear_use$gesture_action, morphs_without_clear_use$gesture_action) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)
```

For the following `r setdiff(morphs_without_clear_use$gesture_action, morphs_with_clear_use$gesture_action) %>% length()` gesture actions, none of the morphs have clear rules:

```{r}
setdiff(morphs_without_clear_use$gesture_action, morphs_with_clear_use$gesture_action) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)
```

This is a summary table for all gesture actions and how their morphs are
distributed to the two types:

```{r}

morph_table <- morphs %>% 
  mutate(is_clear = as.numeric(rules != '')) %>% 
  mutate(is_unclear = as.numeric(rules == '')) %>% 
  group_by(gesture_action) %>% 
  summarise(clear_rule = sum(is_clear),
            no_clear_rule = sum(is_unclear)) %>% 
  ungroup()

morph_table %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)

```

We can therefore differentiate and remove the gesture actions where clear rules determine the morphs, and look more specifically at those where some morphs are not determined by anything in particular. We'll get back to those in a minute, but will look at something else first.

Looking at the entropy measure for whether clusters influence the Goal, we see that `r sum(morphs$entropy.goal == 1)` morphs reduced the entropy about the Goal of the gesture event, indicating that they lead to higher predictability and might have distinct meaning. They occur in `r morphs %>% filter(entropy.goal == 1) %>% distinct(gesture_action, .keep_all = T) %>% nrow()` our of `r morphs %>% distinct(gesture_action, .keep_all = T) %>% nrow()` gesture actions.

### Do morphs of same gesture action cluster in usage?

We can use the Goals as a way to establish whether the different morphs of the same gesture action are more similar in meaning to each other than they are to other gesture actions - if morphs were a useful concept, we'd assume that they at least provide different information than the other morphs for the same gesture action. If the morphs of the same gesture action cluster highly, they are probably not very useful.

The below function establishes the proportion of Goals across all morphs, reduces the dimensions using Latent Class Analysis, and then calculates and plots the Euclidean distance between morphs. There are a couple of different plotting options - we show the network of most similar morphs, where each morph has exactly one most similar morph they are connected with.

```{r sim_morphs, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = TRUE, fig.cap = "Network plot of connection between morphs based on their similarity."}

all_data <- cluster_transposed$full.data %>% 
  purrr::map(~ mutate_if(.x, is.factor, as.character)) %>% 
  purrr::map(~ mutate_if(.x, is.double, as.character)) %>% 
  bind_rows() %>% 
  filter(!is.na(cluster)) %>% 
  unite(morph, Gesture_record, cluster, remove = FALSE)


sim_morphs <- 
  similarity_goals_gestures_new(
    gesture_action = all_data$morph,
    goal = all_data$Goal,
    parameter = 'Gesture', 
    trials = 20, 
    n_epochs = 10000, 
    n_neighbours = 5)

### check predictive model - where would morphs be classified in KNN classifier?

sim_morphs$most.similar.net
```

The graph is a bit overwhelming, but one thing that becomes apparent is that many morphs are similar in usage to other morphs from the same gesture action - in fact, `r (sim_morphs$most.similar %>% separate(Var1, into = c('element', NA), sep = '_') %>% separate(Var2, into = c('most.similar', NA), sep = '_') %>% transmute(same = element == most.similar) %>% unlist() %>%  mean) * 100` % of morphs is most similar to a co-morph, while about  `r (sim_morphs$most.similar %>% separate(Var1, into = c('element', NA), sep = '_') %>% separate(Var2, into = c('most.similar', NA), sep = '_') %>% mutate(most.similar = sample(most.similar)) %>% transmute(same = element == most.similar) %>% unlist() %>%  mean) * 100`% would be expected.

We can also check which morphs are more likely to occur in which context than would be expected for the gesture action as a whole. Here is a network graph mapping the morphs to the Goal, with connections indicating that the observed probability of the morph/Goal combination is higher than would be expected (established analytically using Chi Square tests).

```{r morph_goals_net, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Network plot of connection between morphs and Goals when occurrence is higher than expected."}

goal_net <- 
  lapply(names(cluster_solutions), function(x){
    gg_connection <- 
      gesture_context_analytical(
        data = 
          cluster_solutions[[x]]$full.data %>%
          select(Gesture_record, cluster, Goal) %>% 
          drop_na() %>% 
          filter(!(Goal %in% c('Unknown', 'Other', 'Unclear'))) %>%
          unite(morph, Gesture_record, cluster) %>% 
          rename('Gesture_record' = 'morph'),
        threshold = 1,
        goal_met = FALSE,
        reduce.goals = FALSE,
        reduce.gestures = FALSE)$results %>% 
      data.frame() %>% 
      rename('morph' = 'Gesture_record')}) %>% 
  bind_rows() %>% 
  filter(p <= 0.05 & Prob.increase > 1) %>% 
  arrange(morph, Goal) %>% 
  select(-test.condition,
         -null.condition,
         -Gesture.count, 
         -Goal.count, 
         -Specificity.gesture, 
         -Specificity.goal, 
         -x2, 
         -phi) %>% 
  select(morph, Goal) %>% 
  graph_from_data_frame(
    directed = F,
    vertices = NULL
  )

V(goal_net)$type <-
  bipartite_mapping(goal_net)$type # assign bipartite type as either condition or element

# set colors and shapes
V(goal_net)$color <-
  ifelse(V(goal_net)$type, "salmon", "lightblue") # color set if there are no clusters
V(goal_net)$shape <- ifelse(V(goal_net)$type, "bold", "italic")
# 
# # test for clusters
# net.un <- goal_net
# net.community <-
#   cluster_fast_greedy(net.un) # other clustering algorithms exist, eg walktrap
# modular <-
#   round(modularity(net.community), 2) # modularity measure. Above 0.3 is good modularity
# net.com <- data.frame(
#   element = net.community$names,
#   community = net.community$membership
# )
# color <- rainbow(length(unique(net.com$community)))
# V(goal_net)$color <-
#   color[net.com$community]

all.layout <- create_layout(goal_net,
                            layout = "igraph",
                            algorithm = "nicely"
) # create basic layout that all the graphs will share, so they are symmetrical

p.occurrence <- 
  ggraph(all.layout) +
  geom_node_text(
    mapping = aes(
      color = .data$color,
      label = .data$name,
      size = 20,
      fontface = .data$shape
    ),
    show.legend = FALSE
  ) +
  scale_edge_alpha(guide = "none") +
  theme_graph(base_family = "sans") + # if this is removed, there is bizarrely a constant message telling us that the font does not exist
  # make edges, labels, and arrows
  geom_edge_fan(
    mapping = aes(colour = .data$type),
    label_size = 4,
    arrow = NULL,
    colour = "grey",
    fontface = "bold",
    label_dodge = unit(2, "mm"),
    angle_calc = "along",
    show.legend = F
  ) +
  geom_node_label(
    mapping = aes(
      label = .data$name,
      color = .data$color,
      size = 20,
      fontface = .data$shape
    ),
    show.legend = FALSE
  )

p.occurrence
```

### Predict Goals from Morphs and Gesture Actions

One important function of morphs would be that they help us distinguish between Goals better - theoretically, knowing the morphs should help us make better judgments about the meaning of a gesture. Let's see what happens if we train a Naive Bayes classifier and train it to predict Goals, both with the gesture actions and morphs.

```{r}

morph.data <- cluster_transposed$full.data %>% 
  bind_rows() %>% 
  select(Gesture_record, cluster, Goal) %>% 
  drop_na() %>% 
  unite(morph, Gesture_record, cluster, sep = '.', remove = FALSE) %>% 
  select(Goal, morph, Gesture_record)

# test how well gesture record predicts Goals
gesture.record.prediction <- 
  morph_goal_prediction(predictor = morph.data$Gesture_record,
                        target = morph.data$Goal,
                        out = 100)$result %>% 
  mutate(data = 'Gesture Record')

# test how well morphs predict Goals
morph.prediction <- 
  morph_goal_prediction(predictor = morph.data$morph,
                        target = morph.data$Goal,
                        out = 100)$result %>% 
  mutate(data = 'Morph')

bind_rows(gesture.record.prediction, 
          morph.prediction) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)


```


Looks to me as if, indeed, there is a small increase in prediction accuracy when using the morphs (at least, there is no decrease). This would indicate that using the morphs improves out prediction accuracy.
