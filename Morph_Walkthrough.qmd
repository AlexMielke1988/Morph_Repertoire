---
title: "Morph Repertoire Tutorial"
author: "Alex Mielke, Cat Hobaiter"
date: "`r format(Sys.time(), '%d -%m -%Y')`"
output:
  html_document:
    toc: yes
    df_print: paged
  pdf_document:
    toc: yes
    fig_width: 8
    fig_height: 6
    fig_caption: yes
    number_sections: yes
fontsize: 12pt
spacing: double
fig_caption: yes
indent: yes
geometry: margin=1in
mainfont: Calibri
sansfont: Calibri
monofont: Calibri
editor_options:
  chunk_output_type: console
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      message = FALSE, 
                      warning = FALSE)
options(digits = 3)
library(kableExtra)
library(mclust)
library(knitr)
library(tibble)
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(embed)
library(BayesLCA)
library(discrim)
library(naivebayes)
library(rpart.plot)
library(parallel)
library(doParallel)
```


# Rationale

We are trying to establish a repertoire that provides a useful level of analysis for exploring ape gesture use, one that parses the gestures into units that are relevant to the apes, and one that allows us to describe meaning and explore possible syntax, given the data coded by the Wild Minds Lab. We recognise that other levels of repertoire are possible. For example more fine grained splitting of morphs incorporating more descriptive features, may allow use to explore tone or emphasis. Importantly, there is no 'true' repertoire, as long as we cannot ask the chimpanzees which particles of information they process - we can generate different repertoires of different levels of detail and judge them by their usefulness and internal consistency. By generating the most fine-grained repertoire yet, we can subsequently lump and split depending on the dataset and question at hand. Essentially, for any given level of analysis, we have to show that
every 'gesture' in the coding scheme is exactly one gesture, and that no
two distinct gestures are actually one gesture. Here, we focus on the
first part of that question: are coded gestures actually one gesture and
not several very similar ones, distinguished by some modifying feature?

To move away from a purely *a priori,* human-centred approach, the
coding scheme used by the lab has been changed to not only include a
*gesture action* (the movement pattern that lets human observers detect
the gesture), but also a large number of modifying parameters or
*modifiers.* These specify more detailed aspects of each movement (e.g.,
which limb was used, how far the limb was stretched, etc). The challenge
now is to establish whether there are clustered combinations of gesture
actions and modifiers that would indicate a current gesture action is
indeed two gestures: for example, *arm raise* with one arm vs *arm raise* with both arms. We will refer to the combination of gesture
action and modifiers as **Gesture Morphs**. We will attempt identifying
morphs that could indicate meaningful variation within a gesture action
without referring to the meaning/goal of gestures, and also without
referring to sequential information, because those will be the outcome
variables for later projects - if we involve them here, the risk is our
reasoning becomes tautological.

# Approach

There are currently around 110 gesture actions in the coding scheme and
probably about 8-12 modifiers of interest, many with multiple possible
levels. This would leave us with potentially an astronomically high
number of combinations. One problem we face is that many modifiers are only defined for a small subset of gesture actions - we therefore need rules that are gesture action specific. We will set exclusion rules for both gesture
actions and modifiers. We are trying to create reproducible and replicable definitions of the gesture repertoire, and the dataset for this project continues to expand. 

## A note on the dataset

Here, we are working with a pre-processed and 'anonymised' dataset. 'Anonymised' here means that the gesture actions have numbers rather than names, except for Play because it is relevant for some analyses to distinguish it. This is suboptimal - we would prefer to present all steps from raw data to morph to allow other researchers to replicate those early steps as well (which are often the source of impactful researcher degrees of freedom). However, there was a conflict of interest between following Open Science best practices and the projects of several of the co-authors. Thus, we will present the analytical steps assuming the most of pre-processing has taken place, and gesture action names are altered to prevent publishing the entire database ahead of schedule.

## Ruleset

```{r cutoff, echo = FALSE}
cutoff_overall <- 5 # cutoff for modifiers and morphs
cutoff_action <- 10 # cutoff for gesture actions
```

All rules will be based on probabilities (unconditional and conditional)
and comparisons between observed and expected probability distributions.
We have to set a cutoff value throughout - how many cases of a modifier
level do we have to see to assume we are not simply looking a random
variation or coding error? Here, we set the cutoff at
`r print(cutoff_overall)` for now. This can be varied to check
replicability of this decision.

### Exclusion rules for gesture actions

Gesture actions are only excluded if fewer than `r cutoff_action` cases are available for the gesture action. We included this threshold because we essentially cannot make meaningful statements about the reliability of any morph assignment to these gesture actions, so they represent noise. A list of these can be found below.

### Exclusion rules for modifiers

Modifier levels are excluded within gesture actions if they occur fewer than `r cutoff_overall` times. They are initially lumped into an 'Other' category, but if this category fails to reach `r cutoff_overall` cases, it's set to NA. Modifiers are excluded from analysis within gesture actions if there is no variation in them.

# Data Cleaning

## Get Data and Scripts

```{r libraries}
devtools::load_all("~/GitHub/Morph_Repertoire/wildminds/R/")
```

### Read data into object

First, we read the dataset into an object called 'gesture.data'. This
contains the pre-processed and 'anonymised' data.

```{r read_data, echo = T}
gesture.data <- paper.data
```

### Remove rare gesture actions

Many gesture actions occur at very low frequencies; for example,
`r (gesture.data$Gesture_record %>% table < cutoff_action) %>% sum`
gesture actions occur fewer than `r cutoff_action` times in this
particular dataset. Trying to establish variation within those would be
fairly difficult and hard to justify; thus, we restrict our dataset to
gesture actions that have at least `r cutoff_action` occurrences. The following gesture action are removed:

```{r rare_ga}
(gesture.data$Gesture_record %>% 
                   table)[gesture.data$Gesture_record %>% 
                            table < 
                            cutoff_action] %>% 
  data.frame() %>% 
  rename('Gesture_record' = '.') %>% 
  rename('Frequency' = 'Freq')  %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 12)
  

```


```{r remove_rare}
gesture.data <-
  gesture.data %>%
  filter(Gesture_record %in%
           names(gesture.data$Gesture_record %>%
                   table)[gesture.data$Gesture_record %>%
                            table >=
                            cutoff_action])

```

This leaves us with
`r length(unique(gesture.data$Gesture_record))` instead of
`r length(unique(paper.data$Gesture_record))` gesture actions.

```{r g_data, echo = T}

g.data <- gesture.data %>% 
  select(
    # gesture action
    Gesture_record,
    # modifiers
    Body_part_signaller,
    Body_part_contact,
    Repetition,
    Laterality)

```

After this, g.data has still `r g.data %>% distinct(.keep_all = TRUE) %>% nrow()` unique gesture action/modifier set combinations. That's probably too many to build morphs from directly, because no analyses would be able to process this given the datasets we have. Therefore, we need reliable ways to reduce the information to a manageable set of morphs.

\newpage

# Analysis

## Create probabilities within gesture actions

Let's calculate the basic probabilities of each modifier level within
each gesture action. Please note that all probabilities are dependent on
the modifier being used and any value being assigned; thus, if we have a
gesture action where *Body_part_signaller* was 4 times *NA*, 2 times
'Leg', and 2 times 'Torso', each of the latter two has a probability of
0.5. The 'probability_table' function creates a table that summarises
for each gesture action and each modifier which level was chosen at what
probability. Probabilities should sum up to one within gesture actions
and modifiers - all chosen body parts within *Beckon* should sum to the
entirety of times any body part could be identified.

```{r one_way_gestures, echo = T}

prob.table <- probability_table(data = g.data, 
                                modifiers = colnames(g.data)[-1])

one_way_gestures <- prob.table %>%
  filter(count > 0) %>% 
  group_by(gesture_action) %>% 
  summarise(mean.prob = mean(probability)) %>%
  ungroup() %>% 
  filter(mean.prob == 1) %>% 
  select(gesture_action) %>% 
  unlist %>% as.vector

print(one_way_gestures)
```

Looking at the list, there are currently `r length(one_way_gestures)`
gesture actions that only ever occur in one particular way. Those amount
to
`r (length(one_way_gestures) / length(unique(prob.table$gesture_action))) * 100`%
of all gesture actions in the dataset.

\newpage


## Cluster Detection Algorithms

The main problem with using the probabilities to narrow down the gesture
action/modifier combinations is that each gesture event can be classed
in multiple categories: if *arm raise* differs by repetition (yes/no)
and by laterality (one arm/two arms), then is a case where two arms are repeatedly raised an example of *arm raise - repetition* or *arm raise - two arms*? This would be a real challenge for a repertoire - we
optimally want a solution that assigns each instance exactly one
gesture. We could split it four ways (e.g., one arm/no repetition,
two arms/no repetition, one/yes, two/yes), but this leaves us with very few cases for many of the combinations.

A way to solve this is to use clustering algorithms to find
statistically meaningful hidden underlying or 'latent' classes. We could identify those, see if they provide us with clear reproducible rules how to split a gesture action into morphs, and then determine whether the morphs are useful. This approach could potentially
reduce a lot of variation that we as humans cannot meaningfully handle.
The main problem is that the clustering algorithms are often rather
opaque - we do not always understand why the split occurred the way it.
However, we can identify how the different modifier levels fall into
detected clusters and find those modifier levels that have both a very
high probability of occurring in the cluster (hopefully 1) and a very
high specificity to this cluster (they occur in this cluster and this
cluster only). Modifiers that occur at high probability only in all
clusters (probability = 1, specificity = low) are not very informative;
neither are modifiers that have high specificity but low probability.
Thus, we are trying to find those modifiers that occur in all cases of a
cluster, and differentiate that cluster from others.

Computationally, we use Bayesian Latent Class Analysis (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6364555/) to detect latent classes in the categorical data that are the modifiers. LCA is a model-based cluster detection approach (in contrast to, say, k-means, which is heuristic) - the model quantifies the best split of data given a certain number of assumed clusters and gives us a AIC or BIC value that quantifies the likelihood that the clustering correctly describes some underlying cluster. By repeating the process with multiple cluster sizes and comparing AICs/BICs, we can find the cluster solution that describes the data with the smallest amount of error. We make a second assumption, which is that the best solution is one that only has clusters comprised of at least `r cutoff_overall` cases, our cutoff value.

Here is an example, using *ObjectShake*. Using the probabilistic
approach earlier, we found that *ObjectShake* is differentiated by the
body part used (Hand vs Leg), the Laterality (Alternating vs Both vs
unimanual) and whether the gesture was repeated or not. This would
potentially create a rather large number of possible gestures to split
into, which is something we want to avoid.

```{r cluster_single, echo = TRUE, cache = TRUE}

xx.OS = morph_detection_bayes(
  data = g.data,
  modifiers = colnames(g.data)[-1],
  gesture_action = colnames(g.data)[1],
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall)

```

The current best cluster solution contains
`r xx.OS$cluster.info$cluster %>% max()` clusters. These are
best represented by the following modifiers, which have both high
probability of occurring in this cluster (probability = 1) and high
specificity by not occurring in any of the other clusters (specificity
= 1).

```{r}
xx.OS$cluster.info %>% 
  filter(probability == 1 & 
           specificity == 1) %>% 
  kable(format = 'html',
        row.names = NA,
        align = "c",
        booktabs = T) %>% 
  kable_styling(font_size = 9)
```

Using a network graph, we can visualise the connections between morphs and different modifiers.

```{r object_shake_network, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Bipartite network plot of connection between clusters and important modifiers for ObjectShake."}
plot_bipartite(
  prob.table = xx.OS$cluster.info %>% filter(nr.rules == 1),
  select.modifier = "cluster",
  plot.title = 'ObjectShake',
  cutoff = cutoff_overall,
  threshold = 0
)
```

This approach reduces a lot of the variation compared to the previous
approach. The hierarchical way of splitting the gesture cases means
that each gesture case is assigned to exactly one category while the
number of different clusters is held to a minimum.

```{r object_shake_tree, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Decision tree explaining the clusters and important modifiers for ObjectShake."}

rpart.plot(
      xx.OS$tree,
      type = 4,
      fallen.leaves = FALSE,
      cex = 0.5,
      extra = 0,
      box.palette = "Greys"
    ) %>%
      suppressWarnings()
```

The clustering approach often leads to a relatively large number of
clusters, but it is hard to establish which of these morphs is
potentially an independent source of information and which of them are
potentially just random variation that we introduce by having a detailed
coding scheme. While we try to exclude Meaning as a variable of interest
as much as possible in this analysis, it is worth keeping it in mind
because it will ultimately be the variable that decides whether two
morphs are meaningfully distinct. There are two ways of finding out
which of the morphs are important: first, we can establish which
modifiers could potentially contain relevant information by testing
whether knowledge of the modifier reduces uncertainty about the meaning
of the gesture action very broadly. We would do that by testing whether
the entropy/uncertainty about which Goal the gesture was assigned to is
reduced if the modifier is known (vs randomised). We could then
calculate clusters based only on modifiers for which we have an
indication that they contain relevant information about Meaning.
Alternatively, we use the same approach, but we first determine the
clusters using the maximum set of modifiers, and then test whether any
of the morphs differ from expected with regard to their meaning. We will
present both approaches below for *ObjectShake*.

```{r OS_modifier_entropy}
# use modifier_entropy function to detect which modifiers give us any information about the meaning of the gesture action
entropy.OS = modifier_entropy(
  data = g.data,
  modifiers = colnames(g.data)[-1],
  gesture_action = colnames(g.data)[1],
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall,
  remove_unknown = TRUE,
  target = gesture.data$Goal)

entropy.OS %>% 
  select(modifier,
         level,
         count,
         entropy.observed,
         entropy.expected,
         pvalue.entropy) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

```{r OS_morph_entropy}
# run the same entropy approach but for the clusters - does any of them reduce uncertainty?
entropy.OS.cluster = modifier_entropy(
  data = cbind(xx.OS$full.data,
               GA = rep('ObjectShake', nrow(xx.OS$full.data))),
  modifiers = 'cluster',
  gesture_action = 'GA',
  plot.action = 'ObjectShake',
  cutoff = cutoff_overall,
  target =
    gesture.data$Goal[gesture.data$Gesture_record == 'ObjectShake']
)

entropy.OS.cluster %>%
  select(modifier,
         level,
         count,
         entropy.observed,
         entropy.expected,
         pvalue.entropy) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

## Cluster Detection

What we will do next is essentially to run the cluster algorithm for all
gesture actions, compare them automatically with the probability based
solutions as much as possible and detect the ones for which we need to
check manually which solution would be appropriate. We consider the two
approaches to provide the same solution if the defining modifiers of the
clusters are the same that show variation with the probabilistic
approach, or if both indicate that there is only one cluster. Sometimes
clusters are not based on high probability and specificity of one
modifier, but a combination of two modifiers; where no one-modifier
solution exists, we will provide this information.

**Notes:**

-   The code to run this in parallel and get all the information out is still quite messy.

-   This currently takes about 12h to run on 8 cores


### Run cluster analysis for all gesture actions

```{r, include=FALSE}

# parallelise
mycluster <- makeCluster(16, type = "PSOCK")
# export the relevant information to each core
clusterExport(
  cl = mycluster,
  c(
    "g.data",
    "cutoff_overall",
    "plot_bipartite",
    "probability_table",
    "gesture.data",
    "calculate_prob_of_comb",
    "compute_possible_combs",
    "saveRDS"
  ),
  envir = environment()
)
registerDoParallel(mycluster)
suppressMessages(clusterCall(mycluster, function() library(dplyr)))
suppressMessages(clusterCall(mycluster, function() library(stringr)))
suppressMessages(clusterCall(mycluster, function() library(tidyr)))
suppressMessages(clusterCall(mycluster, function() library(tidytext)))
suppressMessages(clusterCall(mycluster, function() library(tidyfast)))
suppressMessages(clusterCall(mycluster, function() library(tidymodels)))
suppressMessages(clusterCall(mycluster, function() library(embed)))
suppressMessages(clusterCall(mycluster, function() library(plotly)))
suppressMessages(clusterCall(mycluster, function() library(ggplot2)))
suppressMessages(clusterCall(mycluster, function() library(purrr)))
suppressMessages(clusterCall(mycluster, function() library(cluster)))
suppressMessages(clusterCall(mycluster, function() library(BayesLCA)))
suppressMessages(clusterCall(mycluster, function() library(arrangements)))
suppressMessages(clusterCall(mycluster, function() library(Rfast)))
suppressMessages(clusterCall(mycluster, function() library(ggraph)))
suppressMessages(clusterCall(mycluster, function() library(igraph)))
suppressMessages(clusterCall(mycluster, function() library(reshape2)))

```


```{r cluster_solutions, echo=TRUE, warning=FALSE, cache=TRUE, message=FALSE, include=TRUE}

gesture_clusters <- 
  parLapply(mycluster,# go through each gesture action independently
    X = unique(g.data$Gesture_record),
    function(y) {
      devtools::load_all("~/GitHub/Morph_Repertoire/wildminds/R/")   
      library(tidymodels)
      print(y)
      # set action
      action <- y
      # set cutoff
      cutoff.value <- cutoff_overall
      # select gesture action data
      ga.data <- g.data %>%
        filter(Gesture_record == action)
      # store additional info
      ga.identifier <- gesture.data %>%
        filter(Gesture_record == action) %>%
        select(Social_unit, 
               Goal)
      
      # make lca of modifiers
      ga.lca <- 
        morph_detection_bayes(
          data = ga.data,
          modifiers = colnames(ga.data)[-1],
          gesture_action = colnames(ga.data)[1],
          plot.action = action,
          cutoff = cutoff.value
        )
      
      return(ga.lca)
    }
  )

stopCluster(mycluster)

names(gesture_clusters) <- unique(g.data$Gesture_record)
```



### Extract useful information

```{r, include=FALSE}
# calculate basic probabilities
prob.table <- probability_table(data = g.data,
                                modifiers = colnames(g.data)[-1]) %>%
  filter(count > 0)


# run parallel loop

# parallelise
mycluster <- makeCluster(16, type = "PSOCK")
# export the relevant information to each core
clusterExport(
  cl = mycluster,
  c(
    "g.data",
    "prob.table",
    "cutoff_overall",
    "plot_bipartite",
    "probability_table",
    "gesture.data",
    "calculate_prob_of_comb",
    "compute_possible_combs",
    "saveRDS",
    "gesture_clusters"
  ),
  envir = environment()
)
registerDoParallel(mycluster)
suppressMessages(clusterCall(mycluster, function()
  library(dplyr)))
suppressMessages(clusterCall(mycluster, function()
  library(stringr)))
suppressMessages(clusterCall(mycluster, function()
  library(tidyr)))
suppressMessages(clusterCall(mycluster, function()
  library(tidytext)))
suppressMessages(clusterCall(mycluster, function()
  library(tidyfast)))
suppressMessages(clusterCall(mycluster, function()
  library(tidymodels)))
suppressMessages(clusterCall(mycluster, function()
  library(embed)))
suppressMessages(clusterCall(mycluster, function()
  library(plotly)))
suppressMessages(clusterCall(mycluster, function()
  library(ggplot2)))
suppressMessages(clusterCall(mycluster, function()
  library(purrr)))
suppressMessages(clusterCall(mycluster, function()
  library(arrangements)))
suppressMessages(clusterCall(mycluster, function()
  library(Rfast)))
suppressMessages(clusterCall(mycluster, function()
  library(ggraph)))
suppressMessages(clusterCall(mycluster, function()
  library(igraph)))
suppressMessages(clusterCall(mycluster, function()
  library(reshape2)))

```


```{r cluster_solutions_summary, echo=TRUE, warning=FALSE, cache=TRUE, message=FALSE, include=TRUE}

cluster_solutions <-
  parLapply(mycluster, # go through each gesture action independently
            gesture_clusters,
            function(y) {
              devtools::load_all("~/GitHub/Gestures/R package/wildminds/R/")
              print(y$gesture.action)
              ga.lca <- y
              # set action
              action <- ga.lca$gesture.action
              # set cutoff
              cutoff.value <- cutoff_overall
              # select gesture action data
              ga.data <- g.data %>%
                filter(Gesture_record == action)
              # store additional info
              ga.identifier <- gesture.data %>%
                filter(Gesture_record == action) %>%
                select(Social_unit,
                       Goal)
              
              # make a list for summary information
              action.summary <- list()
              action.summary$gesture.action <- action
              action.summary$cutoff <- cutoff.value
              action.summary$count <- nrow(ga.data)
              
              # make probability table for this action
              action.summary$probability.table <-
                prob.table %>%
                filter(gesture_action == action) %>%
                filter(count > 0)
              
              # Check Entropy of goals
              ga.entropy.cluster = modifier_entropy(
                data = ga.lca$full.data %>%
                  mutate(GA = action),
                modifiers = 'cluster',
                gesture_action = 'GA',
                plot.action = action,
                cutoff = cutoff_overall,
                target = ga.identifier$Goal
              )
              
              # Check entropy of modifiers
              
              ga.entropy.modifiers = modifier_entropy(
                data = ga.data,
                modifiers = colnames(ga.data)[-1],
                gesture_action = colnames(ga.data)[1],
                plot.action = action,
                cutoff = cutoff_overall,
                target = ga.identifier$Goal
              )
              
              ### check group patterns
              ga.groups <-
                list(count =
                       table(
                         ga.identifier$Social_unit,
                         ga.lca$full.data$cluster,
                         dnn = c("Group", "Cluster")
                       ))
              
              ga.groups$probability <-
                t(t(ga.groups$count) /
                    colSums(ga.groups$count))
              
              ### Check Goal patterns
              ga.goals <- list(count =
                                 table(
                                   ga.identifier$Goal,
                                   ga.lca$full.data$cluster,
                                   dnn = c("Goal", "Cluster")
                                 ))
              ga.goals$probability <-
                t(t(ga.goals$count) /
                    colSums(ga.goals$count))
              
              
              ### if there is no cluster, return NAs
              if (ga.lca$distinction.info$nr.clusters == 1) {
                action.summary$cluster.solution.number <- 1
                action.summary$cluster.solution.options <- NA
                action.summary$cluster.solution <- NA
                action.summary$cluster.solution.important <- NA
                action.summary$cluster.solution.network <- NA
                action.summary$cluster.solution.tree <- NA
                action.summary$cluster.solution.tree.importance <-
                  NA
                action.summary$group.distribution <- ga.groups
                action.summary$goal.distribution <- ga.goals
                action.summary$full.data <- cbind(ga.data,
                                                  ga.identifier,
                                                  cluster = ga.lca$full.data$cluster)
                action.summary$morph.summary <- NA
                action.summary$entropy.modifiers <- NA
                action.summary$entropy.clusters <- NA
              }
              
              ### If clusters were detected, extract all possible info
              if (ga.lca$distinction.info$nr.clusters > 1) {
                # how many morphs?
                action.summary$cluster.solution.number <-
                  max(ga.lca$cluster.info$cluster %>%
                        as.numeric())
                # how many morphs could have been established?
                action.summary$cluster.solution.options <-
                  ga.lca$solutions
                
                # save individual modifier probability and specificity for morphs
                action.summary$cluster.info <-
                  ga.lca$cluster.info %>%
                  filter(probability > 0)
                
                # save modifiers and combinations that are highly predictive of morphs
                action.summary$cluster.solution.important <-
                  action.summary$cluster.info %>%
                  filter(probability == 1 & specificity == 1) %>%
                  select(modifier) %>%
                  unlist(use.names = FALSE) %>%
                  as.character()
                
                # make lca plot
                action.summary$cluster.solution.network <-
                  plot_bipartite(
                    prob.table = ga.lca$cluster.info %>% filter(nr.rules == 1),
                    select.modifier = "cluster",
                    plot.title = action,
                    cutoff = 0
                  )
                
                # make decision tree plot
                # get variable importance from decision tree
                action.summary$cluster.solution.tree.importance <-
                  ga.lca$tree.var.importance
                
                # save the different distributions by Goal, group, species etc
                action.summary$group.distribution <- ga.groups
                action.summary$species.distribution <- ga.species
                action.summary$coder.distribution <- ga.coder
                action.summary$goal.distribution <- ga.goals
                
                # save full dataset for later use, including addition info
                action.summary$full.data <-
                  cbind(ga.data, ga.identifier, cluster = ga.lca$full.data$cluster)
                
                # check rules for morphs
                
                summary_morphs <- list(
                  ## check which morphs significantly reduced entropy
                  ent.goals = ga.entropy.cluster %>%
                    filter(pvalue.entropy <= 0.05) %>%
                    select(level) %>%
                    unlist(F, F) %>%
                    str_replace('cluster.', ''),
                  ## check which morphs were group specific
                  distinct.group =
                    colnames(ga.groups$count)[ga.groups$probability %>%
                                                apply(2, max) ==
                                                1],
                  ## check which morphs were Goal specific
                  distinct.goal =
                    colnames(ga.goals$count)[ga.goals$probability %>%
                                               apply(2, max) ==
                                               1],
                  ## check which morphs were explained by one modifier level
                  distinct.probability.specificity =
                    ga.lca$cluster.info %>%
                    filter(probability == 1 &
                             specificity == 1) %>%
                    select(cluster) %>%
                    unlist(F, F) %>%
                    as.character() %>%
                    unique(),
                  # cluster count
                  cluster.count =
                    ga.lca$cluster.info %>%
                    distinct(cluster, .keep_all = TRUE) %>%
                    pull(count.cluster)
                )
                
                ## make a summary of the morphs
                morph_sum <- data.frame(cluster =
                                          sort(ga.lca$full.data$cluster %>%
                                                 unique())) %>%
                  mutate(
                    entropy.goal =
                      as.numeric(cluster %in%
                                   summary_morphs$ent.goals),
                    distinct.group =
                      as.numeric(cluster %in%
                                   summary_morphs$distinct.group),
                    distinct.goal =
                      as.numeric(cluster %in%
                                   summary_morphs$distinct.goal)
                  )
                
                # by which of those rules would the morph be considered 'clear'
                morph_sum$rules <-
                  sapply(1:nrow(morph_sum), function(x) {
                    xx <- morph_sum[x, -1]
                    return(paste(colnames(xx)[which(xx == 1)], collapse = ', '))
                  })
                
                morph_sum$gesture_action <- action
                
                # add to action.summary
                action.summary$morph.summary <- morph_sum
                action.summary$entropy.clusters <-
                  ga.entropy.cluster
                action.summary$entropy.modifiers <-
                  ga.entropy.modifiers
              }
              
              # save each run so I don't have to start over every time
              return(action.summary)
            })

stopCluster(mycluster)
```


### Extract from cluster summary

```{r extract_from_summary}
# name elements of list
names(cluster_solutions) <- 
  sapply(cluster_solutions, function(y) y$gesture.action)

# transpose to make more easily accessible
cluster_transposed <- purrr::transpose(cluster_solutions)

cluster_solution_summary <-
  data.frame(
    gesture.action = 
      unlist(cluster_transposed$gesture.action,
             use.names = FALSE),
    count = 
      unlist(cluster_transposed$count,
             use.names = FALSE),
    variation.number = 
      sapply(cluster_transposed$all.variation.cutoff, length),
    cluster.number = 
      unlist(cluster_transposed$cluster.solution.number,
             use.names = FALSE
      ),
    variation.modifiers = 
      sapply(cluster_transposed$all.variation.cutoff, function(x) {
        unlist(x) %>%
          str_split("\\.") %>%
          unlist() %>%
          unique() %>%
          intersect(colnames(g.data)) %>%
          sort() %>%
          paste(collapse = ", ")
      }),
    cluster.modifiers = sapply(
      cluster_transposed$cluster.solution.important, function(x) {
        if (length(x) == 0) {
          return(paste(""))
        }
        x %>%
          unlist() %>%
          str_split("\\.") %>%
          unlist() %>%
          unique() %>%
          intersect(colnames(g.data)) %>%
          sort() %>%
          paste(collapse = ", ")
      }
    )
  )
cluster_solution_summary$variation.number <- ifelse(
  cluster_solution_summary$variation.number == 0,
  1,
  cluster_solution_summary$variation.number
)

distinction.infos <- purrr::transpose(gesture_clusters)$distinction.info

distinction.infos[is.na(distinction.infos)] <- 
  rep(list(data.frame(nr.clusters = 1, 
                      nr.clusters.distinct = 1, 
                      nearest.neighbours = 3)), 
      length(distinction.infos[is.na(distinction.infos)]))

distinction.infos <- distinction.infos %>% 
  bind_rows() %>% 
  mutate(gesture_action = sapply(gesture_clusters, function(y) y$gesture.action)) %>% 
  select(gesture_action, nr.clusters, nr.clusters.distinct) %>% 
  mutate(nr.clusters.unclear = nr.clusters - nr.clusters.distinct)


```

In total, if we go purely with the cluster solution for each gesture
action, we would end up with a repertoire of in total
`r distinction.infos$nr.clusters %>% sum()` morphs, ranging
between 1 and `r distinction.infos$nr.clusters %>% max()` morphs
per gesture action. For most gesture actions, the morphs could be identified using a clear set of rules - for
`r distinction.infos %>% filter(nr.clusters == nr.clusters.distinct) %>% pull(gesture_action) %>% unique() %>% length()` of `r nrow(cluster_solution_summary)` gesture actions, all morphs are clearly defined. The morphs are distributed the following way within the gesture actions:

```{r}
sapply(purrr::transpose(gesture_clusters)$full.data, function(x) max(x$cluster, na.rm = T)) %>% 
  unlist(F,F) %>% 
  table() %>%  
  t() %>%  
  data.frame() %>% 
  select(-Var1) %>% 
  rename('Number_of_moprhs' = '.',
         'Count' = 'Freq') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T) %>% 
  kable_styling(font_size = 9)
```

### Split Rules

If we look at the importance of different modifiers from the random
forest approach, get the following picture for those gesture actions
where splits occurred:

```{r split_importance}
split_importance <- 
  data.frame(variable = 
               cluster_transposed$cluster.solution.tree.importance[
                 sapply(
                   sapply(
                     cluster_transposed$cluster.solution.tree.importance, 
                     is.na), 
                   sum) != 1] %>% 
               sapply(names) %>% 
               unlist() %>% 
               unique() %>% 
               sort()
  )


for(i in seq_along(cluster_transposed$cluster.solution.tree.importance)){
  split_importance <- 
    split_importance %>% 
    left_join(cluster_transposed$cluster.solution.tree.importance[[i]] %>% 
                data.frame(check.names = T) %>% 
                rownames_to_column(var = "variable") %>% 
                rename('importance' = '.') %>% 
                mutate(importance = importance/max(importance))) %>% 
    data.frame() %>% 
    suppressMessages()
  colnames(split_importance)[ncol(split_importance)] = names(cluster_transposed$cluster.solution.tree.importance)[i]
}

split_importance[is.na(split_importance)] = 0

split_importance %>% 
  column_to_rownames('variable') %>% 
  t() %>%
  data.frame() %>%
  rownames_to_column(var = "variable") %>% 
  arrange(variable) %>% 
  column_to_rownames('variable') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

If we plot the average impact of each modifier in gesture actions where
they occur (standardising the impact of all modifiers within gesture
actions by dividing by the sum of all of them, then taking the mean
across all non-NA occurrences of that modifier), we see that there are
clear differences in the importance of modifiers: body part contacted
and laterality seem to lead to clear splits across the gesture actions
in which they occur, while object involved barely matters (mainly
because the gesture actions are already split by object involved), and
Flexion has little impact.

```{r split_importance_plot, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Importance of different modifiers based on random forest assignment."}


xx <- split_importance %>%
  column_to_rownames('variable') %>%
  t() %>%
  data.frame() %>%
  rownames_to_column(var = "variable") %>%
  arrange(variable) %>%
  column_to_rownames('variable')

xx <- xx / rowSums(xx, na.rm = T)

colMeans(xx, na.rm = T) %>%
  data.frame() %>%
  rownames_to_column('modifier') %>%
  rename('Mean_Impact' = '.') %>%
  ggplot(aes(modifier, Mean_Impact)) +
  geom_segment(aes(
    x = modifier,
    xend = modifier,
    y = 0,
    yend = Mean_Impact
  ), color = "grey") +
  geom_point(color = "orange", size = 4) +
  theme_light() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_text(
      angle = 45,
      vjust = 0.5,
      hjust = 0.2
    )
  ) +
  xlab("Modifier") +
  ylab("Mean Impact in Decision Tree")

```

We see that the importance of the modifiers differs drastically - especially the Flexion variables have little impact. We can also confirm this by checking the entropy reduction based on modifiers - across gesture actions, how many times did knowing the level of a modifier make us more certain about the meaning of the signal?

```{r importance_entropy}
entro <- cluster_transposed$entropy.modifiers
entro.names <- names(cluster_transposed$entropy.modifiers)
entro.names <- entro.names[sapply(entro, length) != 1]
entro <- entro[sapply(entro, length) != 1]
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(gesture_action = entro.names[x]))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(modifier = as.character(modifier)))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(level = as.character(level)))
entro <- entro %>%
  bind_rows() %>%
  filter(pvalue.entropy <= 0.05) %>%
  mutate(level = as.character(level)) %>%
  separate(level,
           into = c('mod', 'lev'),
           sep = '\\.',
           remove = FALSE) %>%
  distinct(gesture_action, mod, .keep_all = T)

entro %>% 
  select('gesture_action','mod') %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

Again, we see that there are some modifiers (*Repetition*, *Orientation*, *Flexion*) that only reduce uncertainty for a small number of gesture actions (2 - 4), while *Laterality* and the two body part variables seem to reduce entropy across a range of gesture actions. Only `r entro %>% bind_rows() %>% filter(pvalue.entropy <= 0.05) %>% pull('gesture_action') %>% unique() %>% length()` out of `r gesture.data$Gesture_record %>% unique() %>% length` gesture actions have any modifier that reduces uncertainty at all.

Are there any modifier levels that never do anything?

```{r}
entro <- cluster_transposed$entropy.modifiers
entro.names <- names(cluster_transposed$entropy.modifiers)
entro.names <- entro.names[sapply(entro, length) != 1]
entro <- entro[sapply(entro, length) != 1]
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(gesture_action = entro.names[x]))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(modifier = as.character(modifier)))
entro <- lapply(seq_along(entro), function(x) entro[[x]] %>% mutate(level = as.character(level)))
entro <- entro %>% 
  bind_rows() %>% 
  mutate(sign = as.numeric(pvalue.entropy <= 0.05)) %>% 
  mutate(level = as.character(level)) %>% 
  separate(level, 
           into = c('mod', 'lev'), 
           sep = '\\.', 
           remove = FALSE) %>% 
  group_by(mod, lev) %>% 
  summarise(significance = sum(sign),
            count = sum(count)) %>% 
  data.frame()


entro %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```


## Morphs to keep

The most important rule for morphs should be that within each gesture action, each morph should be defined by one modifier or modifier combination that allows us to assign any case to one morph and one morph only. Here, we check for how many of the morphs this description fits.

```{r}

# get the cluster info tables
cluster_infos <- purrr::transpose(gesture_clusters)$cluster.info
# some gesture actions only have one cluster
gesture_actions_with_one_cluster <- purrr::transpose(gesture_clusters)$gesture.action[
  sapply(cluster_infos, 
         length) == 1] %>% 
  unlist()
#remove gesture actions with only one cluster
cluster_infos <- cluster_infos[sapply(cluster_infos, length) != 1]  
# make table
clear_morphs <- do.call(rbind, cluster_infos) %>% 
  group_by(gesture_action, cluster) %>% 
  summarise(count = max(count.cluster)) %>% 
  ungroup() %>% 
  arrange(gesture_action, cluster) %>% 
  left_join(
    do.call(rbind, cluster_infos)  %>% 
      filter(probability == 1 & specificity == 1) %>% 
      select(gesture_action, cluster) %>% 
      distinct(.keep_all = TRUE) %>%
      mutate(clear.rule = 1)
  ) %>% 
  replace_na(list('clear.rule' = 0))

clear_morphs %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)

```

When we look at the table, we see that only `r clear_morphs %>% filter(clear.rule == 0) %>% nrow()` out of `r nrow(clear_morphs)` morphs are unspecified. In many cases, those are just 'all other' clusters - a category where the clustering algorithm puts combinations that do not fall neatly into any of the other groups. However, for some gesture actions, the situation is more difficult, and the majority of morphs are not defined by one clear rule. One thing to check what to do with these morphs is to check whether there are modifiers and modifier combinations within those gesture actions that could be removed to facilitate the detection of clear patterns (e.g., using the conditionality between modifiers or the entropy approach). A second approach would be to determine whether, despite their not being any modifiers or combinations that perfectly explain a morph, there might be some either/or rules - for example, if a morph is defined perfectly by the signaller using either their hands or their knuckles, and neither of those two ever occurs in any other context, we can still build a replicable rule out of that. Let's check that last point for some of the morphs that were not perfectly specified.

```{r}

additional.rules <- additional_rules(clus_sol = gesture_clusters, 
                                     morphs_nonspec = clear_morphs %>% filter(clear.rule == 0)) 

additional.rules %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 10)

```

There are some additional rules in this - currently, `r additional.rules %>% distinct(gesture_action, cluster) %>% nrow()` additional morphs can be specified this way, usually because there are some rare cases that are classed together because most of the modifiers are otherwise the same (for example, *Body Part Signaller* with Fingers and Knuckles are often classed together). That would leave `r nrow(clear_morphs %>% filter(clear.rule == 0)) - additional.rules %>% distinct(gesture_action, cluster) %>% nrow()` for which no clear pattern is currently available.

### Final Morph Table

What remains from here would be to make a giant table that has the rules for each morph for all the modifiers, so new data could be classified accordingly. That should be achieved by the following code:

```{r morph_rules}

# create data frame that has each morph, their count, and the possible modifiers
morph_rules <- cluster_infos %>%
  bind_rows() %>%
  group_by(gesture_action, cluster) %>%
  summarise(count = max(count.cluster)) %>%
  ungroup() %>%
  arrange(gesture_action, cluster) %>%
  mutate(
    Body_part_signaller = NA,
    Body_part_contact = NA,
    Flexion_wrist = NA,
    Flexion_elbow = NA,
    Orientation = NA,
    Repetition = NA,
    Laterality = NA,
    rule_complexity = 0,
    to_check = 0
  ) %>%
  suppressMessages()

# go through every morph, check whether they are determined by anything
for (i in seq_along(morph_rules$gesture_action)) {
  # select only modifier levels with perfect probability/specificity
  mods <- cluster_infos %>%
    bind_rows() %>%
    filter(
      gesture_action == morph_rules$gesture_action[i] &
        cluster == morph_rules$cluster[i] &
        probability == 1 &
        specificity == 1
    )
  
  # if none exist check additional rules
  if (nrow(mods) == 0) {
    mods <- additional.rules %>%
      filter(
        gesture_action == morph_rules$gesture_action[i] &
          cluster == morph_rules$cluster[i] &
          specificity == 1
      )
  }
  
  # if something exists now, add it
  if (nrow(mods) > 0) {
    # take only simplest rule
    mods <- mods %>%
      filter(nr.rules == min(nr.rules))
    
    # extract info from 'modifier' column
    mod_levels <-
      str_split(str_split(mods$modifier, pattern = ':') %>% unlist()
                ,
                pattern = '\\.')
    
    # add information to table (can have multiple rules)
    for (j in 1:length(mod_levels)) {
      morph_rules[i, mod_levels[[j]][1]] =
        paste(morph_rules[i, mod_levels[[j]][1]],
              mod_levels[[j]][2], sep = ', ')
    }
    morph_rules$rule_complexity[i] = mods$nr.rules %>%
      min()
  }
  
  if (nrow(mods) == 0) {
    morph_rules$to_check[i] = 1
    morph_rules$rule_complexity[i] = 0
  }
  
}

# go through each modifier and remove double-bookings and weird NAs
modifiers = c(
  'Body_part_signaller',
  'Body_part_contact',
  'Flexion_wrist',
  'Flexion_elbow',
  'Orientation',
  'Repetition',
  'Laterality'
)

for (i in modifiers) {
  morph_rules[, i] =
    sapply(morph_rules[, i] %>%
             unlist(), function(x) {
               if (is.na(x)) {
                 return(NA)
               }
               str_split(x, pattern = ', ') %>%
                 unlist(F, F) %>%
                 unique() %>%
                 setdiff('NA') %>%
                 str_c(collapse = '|')
             }) %>% unlist(F, F)
  
}

# add all gesture actions that had only 1 morph or were removed throughout the pipeline
morph_rules_added <-
  clean.data %>%
  group_by(Gesture_record) %>%
  summarise(count = n()) %>%
  ungroup() %>%
  filter(!(Gesture_record %in% morph_rules$gesture_action)) %>%
  rename('gesture_action' = 'Gesture_record') %>%
  mutate(
    cluster = 1,
    Body_part_signaller = NA,
    Body_part_contact = NA,
    Flexion_wrist = NA,
    Flexion_elbow = NA,
    Orientation = NA,
    Repetition = NA,
    Laterality = NA,
    rule_complexity = 0,
    to_check = 0
  )

morph_rules <- bind_rows(morph_rules,
                         morph_rules_added) %>%
  arrange(gesture_action,
          cluster) %>% 
  unite(morph_name, gesture_action, cluster, sep = '.', remove = FALSE)


```

This table has the following arguments: the gesture action, the cluster, the morph name, the count, one column for each modifier (where NA means that this modifier can be discarded, and otherwise the level is reported, with multiple levels split by '|' to express the logical 'OR'), the rule complexity (how many modifiers are involved in identifying the morph), and whether the morph needs checking because no rule could be established.

We can also add information about the groups and goals. We will only add the three most frequent goals.

```{r}

morph_rules$groups <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$group.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        pull(Group) %>% 
        as.character() %>% 
        sort() %>% 
        str_c(collapse = ',')
    }else {
      return(NA)
    }
  })

morph_rules$nr.groups <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$group.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        nrow()
    }else {
      return(NA)
    }
  })


morph_rules$goals <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$goal.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        arrange(desc(Freq)) %>% 
        head(3) %>% 
        pull(Goal) %>% 
        as.character() %>% 
        str_c(collapse = ',')
    }else {
      return(NA)
    }
  })

morph_rules$nr.goals <- 
  sapply(seq_along(morph_rules$morph_name), function(x){
    if(morph_rules$gesture_action[x] %in% names(cluster_solutions)){
      cluster_solutions[[morph_rules$gesture_action[x]]]$goal.distribution$count %>% 
        data.frame() %>% 
        filter(Cluster == morph_rules$cluster[x]) %>% 
        filter(Freq > 0) %>% 
        nrow()
    }else {
      return(NA)
    }
  })


```


```{r}
morph_rules %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 10)
```


What we can also see again from this table is the distribution of modifiers in establishing morphs - overall, *Body Part Signaller* was relevant in `r morph_rules %>% filter(!is.na(Body_part_signaller)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Body Part Contact* was relevant in `r morph_rules %>% filter(!is.na(Body_part_contact)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Flexion Wrist* was relevant in `r morph_rules %>% filter(!is.na(Flexion_wrist)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Flexion Elbow* was relevant in `r morph_rules %>% filter(!is.na(Flexion_elbow)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Orientation* was relevant in `r morph_rules %>% filter(!is.na(Orientation)) %>% distinct(gesture_action) %>% nrow()` gesture actions, *Laterality* was relevant in `r morph_rules %>% filter(!is.na(Laterality)) %>% distinct(gesture_action) %>% nrow()` gesture actions, and *Repetition* was relevant in `r morph_rules %>% filter(!is.na(Repetition)) %>% distinct(gesture_action) %>% nrow()` gesture actions. In terms of complexity of the morph rules (how many modifiers are needed to establish them), here's a little table.


```{r}

morph_rules$rule_complexity %>% 
  table() %>% 
  data.frame() %>% 
  kable(format = 'html',
        col.names = c('Number of Modifiers', 'Frequency'),
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 0) %>% 
  kable_styling(font_size = 10) 

```



\newpage

# Validation

## Morphs of interest

We can determine whether Morphs are an interesting concept by applying some very
basic rules. For examples, let's assume that morphs are useful particles
of communication if they are unique to one group ('distinct.group'), one meaning ('distinct.goal'), or
if they improve our uncertainty about the meaning of the gesture action
(reduced entropy; 'entropy.goal'). These were calculated above, and we can now extract
the morphs that fulfil either of these conditions.

```{r morph_sum}
morphs <- cluster_transposed$morph.summary
morphs <- morphs[sapply(morphs, length) != 1]

morphs <- bind_rows(morphs) %>% 
  mutate_if(is.factor, as.character) %>% 
  mutate_if(is.numeric, as.character)
morphs_unique <- 
  data.frame(cluster = 1, 
             entropy.goal = 1,
             distinct.group = 1, 
             distinct.goal = 1,
             rules = 'onlyMorph',
             gesture_action = names(
               cluster_transposed$morph.summary)[
                 sapply(cluster_transposed$morph.summary, length) == 1]) %>% 
  mutate_if(is.numeric, as.character)

morphs <- bind_rows(morphs, morphs_unique)
morphs_with_clear_use <- morphs %>% 
  filter(rules != '')
morphs_without_clear_use <- morphs %>% 
  filter(rules == '')

morphs_with_clear_use %>% 
  select(gesture_action, cluster, rules) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)

```

For the following `r setdiff(morphs_with_clear_use$gesture_action, morphs_without_clear_use$gesture_action) %>% length()` gesture actions, all morphs have clear rules:

```{r}
setdiff(morphs_with_clear_use$gesture_action, morphs_without_clear_use$gesture_action) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)
```

For the following `r setdiff(morphs_without_clear_use$gesture_action, morphs_with_clear_use$gesture_action) %>% length()` gesture actions, none of the morphs have clear rules:

```{r}
setdiff(morphs_without_clear_use$gesture_action, morphs_with_clear_use$gesture_action) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 9)
```

This is a summary table for all gesture actions and how their morphs are
distributed to the two types:

```{r}

morph_table <- morphs %>% 
  mutate(is_clear = as.numeric(rules != '')) %>% 
  mutate(is_unclear = as.numeric(rules == '')) %>% 
  group_by(gesture_action) %>% 
  summarise(clear_rule = sum(is_clear),
            no_clear_rule = sum(is_unclear)) %>% 
  ungroup()

morph_table %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)

```

We can therefore differentiate and remove the gesture actions where clear rules determine the morphs, and look more specifically at those where some morphs are not determined by anything in particular. We'll get back to those in a minute, but will look at something else first.

Looking at the entropy measure for whether clusters influence the Goal, we see that `r sum(morphs$entropy.goal == 1)` morphs reduced the entropy about the Goal of the gesture event, indicating that they lead to higher predictability and might have distinct meaning. They occur in `r morphs %>% filter(entropy.goal == 1) %>% distinct(gesture_action, .keep_all = T) %>% nrow()` our of `r morphs %>% distinct(gesture_action, .keep_all = T) %>% nrow()` gesture actions.

### Do morphs of same gesture action cluster in usage?

We can use the Goals as a way to establish whether the different morphs of the same gesture action are more similar in meaning to each other than they are to other gesture actions - if morphs were a useful concept, we'd assume that they at least provide different information than the other morphs for the same gesture action. If the morphs of the same gesture action cluster highly, they are probably not very useful.

The below function establishes the proportion of Goals across all morphs, reduces the dimensions using Latent Class Analysis, and then calculates and plots the Euclidean distance between morphs. There are a couple of different plotting options - we show the network of most similar morphs, where each morph has exactly one most similar morph they are connected with.

```{r sim_morphs, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = TRUE, fig.cap = "Network plot of connection between morphs based on their similarity."}

all_data <- cluster_transposed$full.data %>% 
  purrr::map(~ mutate_if(.x, is.factor, as.character)) %>% 
  purrr::map(~ mutate_if(.x, is.double, as.character)) %>% 
  bind_rows() %>% 
  filter(!is.na(cluster)) %>% 
  unite(morph, Gesture_record, cluster, remove = FALSE)


sim_morphs <- 
  similarity_goals_gestures_new(
    gesture_action = all_data$morph,
    goal = all_data$Goal,
    parameter = 'Gesture', 
    trials = 20, 
    n_epochs = 10000, 
    n_neighbours = 5)

### check predictive model - where would morphs be classified in KNN classifier?

sim_morphs$most.similar.net
```

The graph is a bit overwhelming, but one thing that becomes apparent is that many morphs are similar in usage to other morphs from the same gesture action - in fact, `r (sim_morphs$most.similar %>% separate(Var1, into = c('element', NA), sep = '_') %>% separate(Var2, into = c('most.similar', NA), sep = '_') %>% transmute(same = element == most.similar) %>% unlist() %>%  mean) * 100` % of morphs is most similar to a co-morph, while about  `r (sim_morphs$most.similar %>% separate(Var1, into = c('element', NA), sep = '_') %>% separate(Var2, into = c('most.similar', NA), sep = '_') %>% mutate(most.similar = sample(most.similar)) %>% transmute(same = element == most.similar) %>% unlist() %>%  mean) * 100`% would be expected.

We can also check which morphs are more likely to occur in which context than would be expected for the gesture action as a whole. Here is a network graph mapping the morphs to the Goal, with connections indicating that the observed probability of the morph/Goal combination is higher than would be expected (established analytically using Chi Square tests).

```{r morph_goals_net, fig.align='center', fig.width=12, fig.height=12, message=F, echo = TRUE, cache = FALSE, fig.cap = "Network plot of connection between morphs and Goals when occurrence is higher than expected."}

goal_net <- 
  lapply(names(cluster_solutions), function(x){
    gg_connection <- 
      gesture_context_analytical(
        data = 
          cluster_solutions[[x]]$full.data %>%
          select(Gesture_record, cluster, Goal) %>% 
          drop_na() %>% 
          filter(!(Goal %in% c('Unknown', 'Other', 'Unclear'))) %>%
          unite(morph, Gesture_record, cluster) %>% 
          rename('Gesture_record' = 'morph'),
        threshold = 1,
        goal_met = FALSE,
        reduce.goals = FALSE,
        reduce.gestures = FALSE)$results %>% 
      data.frame() %>% 
      rename('morph' = 'Gesture_record')}) %>% 
  bind_rows() %>% 
  filter(p <= 0.05 & Prob.increase > 1) %>% 
  arrange(morph, Goal) %>% 
  select(-test.condition,
         -null.condition,
         -Gesture.count, 
         -Goal.count, 
         -Specificity.gesture, 
         -Specificity.goal, 
         -x2, 
         -phi) %>% 
  select(morph, Goal) %>% 
  graph_from_data_frame(
    directed = F,
    vertices = NULL
  )

V(goal_net)$type <-
  bipartite_mapping(goal_net)$type # assign bipartite type as either condition or element

# set colors and shapes
V(goal_net)$color <-
  ifelse(V(goal_net)$type, "salmon", "lightblue") # color set if there are no clusters
V(goal_net)$shape <- ifelse(V(goal_net)$type, "bold", "italic")
# 
# # test for clusters
# net.un <- goal_net
# net.community <-
#   cluster_fast_greedy(net.un) # other clustering algorithms exist, eg walktrap
# modular <-
#   round(modularity(net.community), 2) # modularity measure. Above 0.3 is good modularity
# net.com <- data.frame(
#   element = net.community$names,
#   community = net.community$membership
# )
# color <- rainbow(length(unique(net.com$community)))
# V(goal_net)$color <-
#   color[net.com$community]

all.layout <- create_layout(goal_net,
                            layout = "igraph",
                            algorithm = "nicely"
) # create basic layout that all the graphs will share, so they are symmetrical

p.occurrence <- 
  ggraph(all.layout) +
  geom_node_text(
    mapping = aes(
      color = .data$color,
      label = .data$name,
      size = 20,
      fontface = .data$shape
    ),
    show.legend = FALSE
  ) +
  scale_edge_alpha(guide = "none") +
  theme_graph(base_family = "sans") + # if this is removed, there is bizarrely a constant message telling us that the font does not exist
  # make edges, labels, and arrows
  geom_edge_fan(
    mapping = aes(colour = .data$type),
    label_size = 4,
    arrow = NULL,
    colour = "grey",
    fontface = "bold",
    label_dodge = unit(2, "mm"),
    angle_calc = "along",
    show.legend = F
  ) +
  geom_node_label(
    mapping = aes(
      label = .data$name,
      color = .data$color,
      size = 20,
      fontface = .data$shape
    ),
    show.legend = FALSE
  )

p.occurrence
```

### Predict Goals from Morphs and Gesture Actions

One important function of morphs would be that they help us distinguish between Goals better - theoretically, knowing the morphs should help us make better judgments about the meaning of a gesture. Let's see what happens if we train a Naive Bayes classifier and train it to predict Goals, both with the gesture actions and morphs.

```{r}

morph.data <- cluster_transposed$full.data %>% 
  bind_rows() %>% 
  select(Gesture_record, cluster, Goal) %>% 
  drop_na() %>% 
  unite(morph, Gesture_record, cluster, sep = '.', remove = FALSE) %>% 
  select(Goal, morph, Gesture_record)

# test how well gesture record predicts Goals
gesture.record.prediction <- 
  morph_goal_prediction(predictor = morph.data$Gesture_record,
                        target = morph.data$Goal,
                        out = 100)$result %>% 
  mutate(data = 'Gesture Record')

# test how well morphs predict Goals
morph.prediction <- 
  morph_goal_prediction(predictor = morph.data$morph,
                        target = morph.data$Goal,
                        out = 100)$result %>% 
  mutate(data = 'Morph')

bind_rows(gesture.record.prediction, 
          morph.prediction) %>% 
  kable(format = 'html', 
        row.names = NA,
        align = "c",
        booktabs = T, 
        digits = 2) %>% 
  kable_styling(font_size = 12)


```


Looks to me as if, indeed, there is a small increase in prediction accuracy when using the morphs (at least, there is no decrease). This would indicate that using the morphs improves out prediction accuracy.
